{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utility import *\n",
    "from data_utils import get_dimensions\n",
    "from model import *\n",
    "from loss import *\n",
    "from train import *\n",
    "from sync_batchnorm import convert_model\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "NUM_WORKERS = 6\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "dtype = torch.float32 \n",
    "# define dtype, float is space efficient than double\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # magic flag that accelerate\n",
    "    \n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pyramid_dataset(data_type = 'nii_train', \n",
    "                transform=transforms.Compose([\n",
    "                random_affine(90, 15),\n",
    "                random_filp(0.5)]))\n",
    "# do data augumentation on train dataset\n",
    "\n",
    "validation_dataset = pyramid_dataset(data_type = 'nii_test', \n",
    "                transform=None)\n",
    "# no data augumentation on validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "# loaders come with auto batch division and multi-thread acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv3d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "    elif isinstance(m, nn.BatchNorm3d):\n",
    "        init.normal_(m.weight.data, mean=0, std=1)\n",
    "\n",
    "def downsample_label(label, scale_factor):\n",
    "    return F.interpolate(label, scale_factor=scale_factor, mode='trilinear', align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_test(model, cuda_bool):\n",
    "    x = torch.zeros((1, 1, 256, 256, 256))\n",
    "    x = x.to(device=device, dtype=dtype) if cuda_bool else x\n",
    "    scores = model(x)\n",
    "    for i in scores:\n",
    "        print(i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#icnet1 = FullResolutionICNet(num_classes=3)\n",
    "#icnet1 = nn.DataParallel(icnet1)\n",
    "#icnet1 = convert_model(icnet1)\n",
    "##icnet1.apply(init_weights)\n",
    "#icnet1 = icnet1.to(device=device, dtype=dtype)\n",
    "#shape_test(icnet1, True)\n",
    "# create the model, by default model type is float, use model.double(), model.float() to convert\n",
    "# move the model to desirable device\n",
    "\n",
    "#optimizer1 = optim.Adam(icnet1.parameters(), lr=1e-2)\n",
    "# create an optimizer object\n",
    "# note that only the model_2 params and model_4 params will be optimized by optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icnet1 = FullResolutionICNet(num_classes=3)\n",
    "icnet1 = nn.DataParallel(icnet1)\n",
    "icnet1 = convert_model(icnet1)\n",
    "optimizer1 = optim.Adam(icnet1.parameters(), lr=1e-2)\n",
    "\n",
    "checkpoint = torch.load('../full_res_save/2019-07-28 21:54:09.866803.pth')\n",
    "\n",
    "icnet1.load_state_dict(checkpoint['state_dict_1'])\n",
    "icnet1 = icnet1.to(device=device, dtype=dtype)\n",
    "\n",
    "optimizer1.load_state_dict(checkpoint['optimizer'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4761 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239 finished ! Training Loss: 0.7247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/4761 [08:02<638:16:40, 482.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.2253\n",
      "\n",
      "Checkpoint 239 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/4761 [13:38<580:01:40, 438.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240 finished ! Training Loss: 0.7411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/4761 [19:18<540:37:53, 409.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241 finished ! Training Loss: 0.7299\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/4761 [24:55<511:51:09, 387.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242 finished ! Training Loss: 0.7390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "record = open('train_new_full_res_model_upsampled.txt','a')\n",
    "\n",
    "logger = {'train':[], 'validation_1':[]}\n",
    "\n",
    "for e in tqdm(range(epoch, epochs)):\n",
    "# iter over epoches\n",
    "\n",
    "    epoch_loss = 0\n",
    "        \n",
    "    for t, batch in enumerate(train_loader):\n",
    "    # iter over the train mini batches\n",
    "    \n",
    "        icnet1.train()\n",
    "        # Set the model flag to train\n",
    "        # 1. enable dropout\n",
    "        # 2. batchnorm behave differently in train and test\n",
    "        \n",
    "        image_4 = batch['image4_data'].to(device=device, dtype=dtype)\n",
    "        label_4 = batch['image4_label'].to(device=device, dtype=dtype)\n",
    "        \n",
    "        image_2 = batch['image2_data'].to(device=device, dtype=dtype)\n",
    "        label_2 = batch['image2_label'].to(device=device, dtype=dtype)\n",
    "        \n",
    "        image_1 = batch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = batch['image1_label'].to(device=device, dtype=dtype)\n",
    "        # move data to device, convert dtype to desirable dtype\n",
    "        \n",
    "        # Downsample labels to coincide with icnet model outputs\n",
    "        #label_1_resize_2 = downsample_label(label_1, 1/2)\n",
    "        #label_2_resize_2 = downsample_label(label_2, 1/2)\n",
    "        #label_4_resize_2 = downsample_label(label_4, 1/2)\n",
    "        \n",
    "        out_1, out_2, out_4 = icnet1(image_1)\n",
    "        # do the inference\n",
    "\n",
    "        #loss_4 = dice_loss_3(out_4, label_4_resize_2)\n",
    "        #loss_2 = dice_loss_3(out_2, label_2_resize_2)\n",
    "        loss_4 = dice_loss_3(out_4, label_4)\n",
    "        loss_2 = dice_loss_3(out_2, label_2)\n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "        # calculate loss\n",
    "\n",
    "        loss = loss_4 + loss_2 + loss_1 \n",
    "        # add loss\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        # record minibatch loss to epoch loss\n",
    "        \n",
    "        optimizer1.zero_grad()\n",
    "        # set the model parameter gradient to zero\n",
    "        \n",
    "        loss.backward()\n",
    "        # calculate the gradient wrt loss\n",
    "        \n",
    "        optimizer1.step()\n",
    "        #scheduler.step(loss)\n",
    "        # take a gradient descent step\n",
    "        \n",
    "    outstr = 'Epoch {0} finished ! Training Loss: {1:.4f}'.format(e, epoch_loss/(t+1)) + '\\n'\n",
    "    \n",
    "    logger['train'].append(epoch_loss/(t+1))\n",
    "    \n",
    "    print(outstr)\n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "\n",
    "    if e%5 == 4:\n",
    "    # do validation every 5 epoches\n",
    "    \n",
    "        icnet1.eval()\n",
    "        # set model flag to eval\n",
    "        # 1. disable dropout\n",
    "        # 2. batchnorm behave differs\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # stop taking gradient\n",
    "        \n",
    "            #valloss_4 = 0\n",
    "            #valloss_2 = 0\n",
    "            valloss_1 = 0\n",
    "            \n",
    "            for v, vbatch in enumerate(validation_loader):\n",
    "            # iter over validation mini batches\n",
    "            \n",
    "                #image_4_val = vbatch['image4_data'].to(device=device, dtype=dtype)\n",
    "                #if get_dimensions(image_4_val) == 4:\n",
    "                #    image_4_val.unsqueeze_(0)\n",
    "                #label_4_val = vbatch['image4_label'].to(device=device, dtype=dtype)\n",
    "                #if get_dimensions(label_4_val) == 4:\n",
    "                #    label_4_val.unsqueeze_(0)\n",
    "                \n",
    "                #image_2_val = vbatch['image2_data'].to(device=device, dtype=dtype)\n",
    "                #if get_dimensions(image_2_val) == 4:\n",
    "                #    image_2_val.unsqueeze_(0)\n",
    "                #label_2_val = vbatch['image2_label'].to(device=device, dtype=dtype)\n",
    "                #if get_dimensions(label_2_val) == 4:\n",
    "                #    label_2_val.unsqueeze_(0)\n",
    "                \n",
    "                image_1_val = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "                if get_dimensions(image_1_val) == 4:\n",
    "                    image_1_val.unsqueeze_(0)\n",
    "                label_1_val = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "                if get_dimensions(label_1_val) == 4:\n",
    "                    label_1_val.unsqueeze_(0)\n",
    "                \n",
    "                #print(\"image_1_val:\", image_1_val.shape)\n",
    "                #print(\"label_1_val:\", label_1_val.shape)\n",
    "                # move data to device, convert dtype to desirable dtype\n",
    "                # add dimension to labels if they are 4D tensors\n",
    "                \n",
    "                # Downsample labels to coincide with icnet model outputs\n",
    "                #label_1_val_resize_2 = downsample_label(label_1_val, 1/2) \n",
    "                #label_2_val_resize_2 = downsample_label(label_2_val, 1/2) \n",
    "                #label_4_val_resize_2 = downsample_label(label_4_val, 1/2) \n",
    "                #print(\"label_1_val_resize:\", label_1_val_resize_2.shape) \n",
    "                \n",
    "                out_1_val = icnet1(image_1_val)\n",
    "                # do the inference\n",
    "                \n",
    "                #print(\"out_4:\", out_4_val.shape)\n",
    "                #print(\"label_4:\", label_4_val_resize_2.shape)\n",
    "                #loss_4 = dice_loss_3(out_4_val, label_4_val_resize_2)\n",
    "                #loss_2 = dice_loss_3(out_2_val, label_2_val_resize_2)\n",
    "                loss_1 = dice_loss_3(out_1_val, label_1_val)\n",
    "                # calculate loss\n",
    "\n",
    "                #valloss_4 += loss_4.item()\n",
    "                #valloss_2 += loss_2.item()\n",
    "                valloss_1 += loss_1.item()\n",
    "                # record mini batch loss\n",
    "            \n",
    "            outstr = '------- 1st valloss={0:.4f}'\\\n",
    "                .format(valloss_1/(v+1)) + '\\n'\n",
    "            \n",
    "            logger['validation_1'].append(valloss_1/(v+1))\n",
    "            \n",
    "            print(outstr)\n",
    "            record.write(outstr)\n",
    "            record.flush()\n",
    "            \n",
    "            scheduler.step(valloss_1/(v+1))\n",
    "            \n",
    "            save_1('full_res_save', icnet1, optimizer1, logger, e)\n",
    "\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
