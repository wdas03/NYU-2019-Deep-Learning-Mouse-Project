{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utility import *\n",
    "from data_utils import *\n",
    "from loss import *\n",
    "from train import *\n",
    "from deeplab_model.deeplab import *\n",
    "from dense_vnet.DenseVNet import DenseVNet\n",
    "from sync_batchnorm import convert_model\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "NUM_WORKERS = 12\n",
    "BATCH_SIZE = 2 \n",
    "\n",
    "dtype = torch.float32 \n",
    "# define dtype, float is space efficient than double\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # magic flag that accelerate\n",
    "    \n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_full_resolution_dataset(data_type = 'nii_train', \n",
    "                transform=transforms.Compose([\n",
    "                random_affine(90, 15),\n",
    "                random_filp(0.5)]))\n",
    "# do data augumentation on train dataset\n",
    "\n",
    "validation_dataset = get_full_resolution_dataset(data_type = 'nii_test', \n",
    "                transform=None)\n",
    "# no data augumentation on validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS) # drop_last\n",
    "# loaders come with auto batch division and multi-thread acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "from bv_refinement_network.RefinementModel import RefinementModel, RefinementModel_NoDown\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    \n",
    "refine_model = RefinementModel(num_classes=1)\n",
    "refine_model = nn.DataParallel(refine_model)\n",
    "refine_model = convert_model(refine_model)\n",
    "refine_model = refine_model.to(device, dtype)\n",
    "\n",
    "optimizer = optim.Adam(refine_model.parameters(), lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=25)\n",
    "\n",
    "deeplab = DeepLab(output_stride=16)\n",
    "deeplab = nn.DataParallel(deeplab)\n",
    "deeplab = convert_model(deeplab)\n",
    "\n",
    "checkpoint = torch.load('../deeplab_dilated_save/2019-08-10 09:28:43.844872 epoch: 1160.pth') # best one\n",
    "\n",
    "deeplab.load_state_dict(checkpoint['state_dict_1'])\n",
    "deeplab = deeplab.to(device, dtype)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dictionary = train_dataset[33]\n",
    "\n",
    "image_1 = test_dictionary['image1_data'].view(1, 1, 256, 256, 256)\n",
    "label_1 = test_dictionary['image1_label'].view(1, 3, 256, 256, 256)\n",
    "bv_label = label_1.narrow(1,2,1).to(device, dtype)\n",
    "if get_dimensions(bv_label) == 4:\n",
    "    bv_label.unsqueeze_(0)\n",
    "\n",
    "image_1 = image_1.to(device=device, dtype=dtype) \n",
    "label_1 = label_1.to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subvolumes(whole_img,whole_label,box_size=64,largest_ratio=0.8,step_size=3):\n",
    "    img_size=np.shape(whole_img)\n",
    "    bv_voxel_num=np.sum(whole_label)\n",
    "    sub_volumes=[]\n",
    "    \n",
    "    x_start = box_size\n",
    "    x_stop = img_size[0]\n",
    "    \n",
    "    y_start = box_size\n",
    "    y_stop = img_size[1]\n",
    "    \n",
    "    z_start = box_size\n",
    "    z_stop = img_size[2]\n",
    "    \n",
    "    for i in range(x_start,x_stop+1,step_size):\n",
    "        for j in range(y_start,y_stop+1,step_size):\n",
    "            for k in range(z_start,z_stop+1,step_size):\n",
    "                if (np.sum(whole_label[i-box_size:i,\n",
    "                                j-box_size:j,\n",
    "                                k-box_size:k])/(bv_voxel_num+0.001)) < largest_ratio:\n",
    "                    sub_volumes.append((0,(i,j,k)))\n",
    "                else:\n",
    "                    sub_volumes.append((1,(i,j,k)))\n",
    "    return sub_volumes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_localization_and_label(image, label, output, batchsize):\n",
    "    image = image.cpu().detach().numpy()\n",
    "    label = label.cpu().detach().numpy()\n",
    "    output = output.cpu().detach().numpy()\n",
    "    \n",
    "    xslice = np.zeros((batchsize, 1, 128, 128, 128)) - 64 #same mean removal\n",
    "    yslice = np.zeros((batchsize, 1, 128, 128, 128))\n",
    "    bv_slice = np.zeros((batchsize, 1, 128, 128, 128))\n",
    "    \n",
    "    #print(xslice.shape)\n",
    "    #print(yslice.shape)\n",
    "    #print(bv_slice.shape)\n",
    "    \n",
    "    yhat = binarize_output(output).view(batchsize, 1, 256, 256, 256)\n",
    "    yhat = yhat.cpu().detach().numpy()\n",
    "    out = np.zeros((batchsize, 6))\n",
    "    #print(yhat.shape)\n",
    "    #print(yhat[0].shape)\n",
    "    #print(out.shape)\n",
    "    for b in range(batchsize):\n",
    "        out[b] = loadbvmask(yhat[b])\n",
    "    yhat = out\n",
    "                        \n",
    "    xcenter = np.mean(yhat[:,0:2], axis=1)\n",
    "    ycenter = np.mean(yhat[:,2:4], axis=1)\n",
    "    zcenter = np.mean(yhat[:,4:6], axis=1)\n",
    "\n",
    "    xcenter, ycenter, zcenter = np.clip ([xcenter, ycenter, zcenter], a_min=32, a_max=96)\n",
    "\n",
    "    yhat[:,0] = xcenter - 32\n",
    "    yhat[:,0] = np.max((yhat[:,0], 0))\n",
    "\n",
    "    yhat[:,2] = ycenter - 32\n",
    "    yhat[:,2] = np.max((yhat[:,2], 0))\n",
    "\n",
    "    yhat[:,4] = zcenter - 32\n",
    "    yhat[:,4] = np.max((yhat[:,4], 0))\n",
    "\n",
    "    yhat[:,1] = xcenter + 32\n",
    "    yhat[:,1] = np.min((yhat[:,1], 128))\n",
    "\n",
    "    yhat[:,3] = ycenter + 32\n",
    "    yhat[:,3] = np.min((yhat[:,3], 128))\n",
    "\n",
    "    yhat[:,5] = zcenter + 32\n",
    "    yhat[:,5] = np.min((yhat[:,5], 128))\n",
    "\n",
    "    yhat = np.round(yhat)*2\n",
    "    \n",
    "    #print(yhat.shape)\n",
    "\n",
    "    ###\n",
    "\n",
    "    for b in range(BATCH_SIZE):\n",
    "        xh1, xh2, yh1, yh2, zh1, zh2 = yhat[b]\n",
    "        xh1, xh2, yh1, yh2, zh1, zh2 = int(xh1), int(xh2), int(yh1), int(yh2), int(zh1), int(zh2)\n",
    "        \n",
    "        xslice[b] = image[b, :, xh1:xh2, yh1:yh2, zh1:zh2]\n",
    "        yslice[b] = label[b, :, xh1:xh2, yh1:yh2, zh1:zh2]\n",
    "        bv_slice[b] = output[b, :, xh1:xh2, yh1:yh2, zh1:zh2] \n",
    "\n",
    "        #xslice[b] = image[b, :, xx1:xx1+128, yy1:yy1+128, zz1:zz1+128]\n",
    "        #yslice[b] = label[b, :, xx1:xx1+128, yy1:yy1+128, zz1:zz1+128]\n",
    "        #bv_slice[b] = output[b, :, xx1:xx1+128, yy1:yy1+128, zz1:zz1+128]\n",
    "\n",
    "    xslice = torch.from_numpy(xslice)            \n",
    "    xslice = xslice.to(device=device, dtype=dtype)\n",
    "\n",
    "    return xslice, torch.from_numpy(yslice).to(device, dtype), torch.from_numpy(bv_slice).to(device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(image, label, output, batchsize):\n",
    "    image_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    label_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    output_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    for b in range(batchsize):\n",
    "        out = output[b]\n",
    "        x, y, z = find_bv_centroid(binarize_output(out))\n",
    "        #x,y,z = loadbvcenter(binarize_output(out))\n",
    "        x, y, z = np.clip([x, y, z], a_min=64, a_max=192)\n",
    "        x1 = max(x-64, 0)\n",
    "        x2 = min(x+64, 256)\n",
    "        y1 = max(y-64, 0)\n",
    "        y2 = min(y+64, 256)\n",
    "        z1 = max(z-64, 0)\n",
    "        z2 = min(z+64, 256)\n",
    "        image_final[b] = image[b, :, x1:x2, y1:y2, z1:z2]\n",
    "        label_final[b] = label[b, :, x1:x2, y1:y2, z1:z2]\n",
    "        output_final[b] = output[b, :, x1:x2, y1:y2, z1:z2]\n",
    "    return image_final, label_final, output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9799, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9702, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9432, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9325, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9617, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8830, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8962, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8389, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8338, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8517, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7253, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7769, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9580, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6866, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9540, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5905, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6449, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6209, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5620, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8169, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4075, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4226, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3077, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6511, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7670, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8423, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5438, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6099, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6661, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7105, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6017, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6951, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7048, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8007, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5946, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4507, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8928, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3624, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5994, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9958, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4875, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5381, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7456, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5948, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5844, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4489, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5649, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6099, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4345, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6442, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5238, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7129, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5737, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3988, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4334, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4739, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4103, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9654, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5789, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5131, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5963, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3199, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6324, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9646, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3444, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9926, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3974, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/4999 [13:08<1094:21:09, 788.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished ! Training Loss: 0.6655\n",
      "\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2979, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3712, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4346, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6443, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8170, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7069, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2912, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7246, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1970, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6622, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5800, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4436, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6065, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7546, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7444, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6706, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2208, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3227, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6618, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3880, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7797, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2616, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3853, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5766, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2857, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4752, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2547, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4889, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4009, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6367, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3031, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3192, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6326, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2580, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1925, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3236, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4504, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5126, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1988, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6498, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6235, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2021, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2189, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5806, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2610, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6318, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9983, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3949, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6745, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7153, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2934, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5357, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5964, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6456, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2743, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3144, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6526, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4577, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2949, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7404, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3284, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4555, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6613, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3576, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 2 finished ! Training Loss: 0.4964\n",
      "\n",
      "tensor(0.3228, device='cuda:0')\n",
      "tensor(0.2104, device='cuda:0')\n",
      "tensor(0.2051, device='cuda:0')\n",
      "tensor(0.3321, device='cuda:0')\n",
      "tensor(0.3820, device='cuda:0')\n",
      "tensor(0.3363, device='cuda:0')\n",
      "tensor(0.3562, device='cuda:0')\n",
      "tensor(0.2924, device='cuda:0')\n",
      "tensor(0.3067, device='cuda:0')\n",
      "tensor(0.2732, device='cuda:0')\n",
      "tensor(0.3618, device='cuda:0')\n",
      "tensor(0.3532, device='cuda:0')\n",
      "tensor(0.3010, device='cuda:0')\n",
      "tensor(0.2914, device='cuda:0')\n",
      "tensor(0.4890, device='cuda:0')\n",
      "tensor(0.2026, device='cuda:0')\n",
      "tensor(0.2766, device='cuda:0')\n",
      "tensor(0.2927, device='cuda:0')\n",
      "tensor(0.3717, device='cuda:0')\n",
      "tensor(0.4270, device='cuda:0')\n",
      "tensor(0.1880, device='cuda:0')\n",
      "tensor(0.2809, device='cuda:0')\n",
      "tensor(0.2639, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/4999 [25:36<1077:35:25, 776.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 2 saved !\n",
      "------- 1st valloss=0.3094\n",
      "\n",
      "tensor(0.3136, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3640, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3168, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4871, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1925, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5945, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5748, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3637, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6503, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6421, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3036, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8443, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2619, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2530, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3107, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5989, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7130, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3375, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2607, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1913, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3221, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1895, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3074, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6119, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6269, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4298, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4549, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2690, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3534, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5907, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1982, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8354, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5842, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2315, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4176, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "record = open('train_bv_refine_5.txt','a+')\n",
    "\n",
    "logger = {'train':[], 'validation_1': []}\n",
    "\n",
    "min_val = 1\n",
    "\n",
    "for e in tqdm(range(epoch + 1, epochs)):\n",
    "# iter over epoches\n",
    "    epoch_loss = 0\n",
    "        \n",
    "    for t, batch in enumerate(train_loader):\n",
    "    # iter over the train mini batches\n",
    "        refine_model.train()\n",
    "        deeplab.eval()\n",
    "        # Set the model flag to train\n",
    "        # 1. enable dropout\n",
    "        # 2. batchnorm behave differently in train and test\n",
    "        #print(batch['image1_data'])\n",
    "        image_1 = batch['image1_data'].to(device=device, dtype=dtype)\n",
    "        image_1 = image_1.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        label_1 = batch['image1_label'].to(device=device, dtype=dtype)\n",
    "        label_1 = label_1.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "        bv_label = label_1[:, 2, :, :, :]\n",
    "        bv_label = bv_label.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        #original_res = [a[minibatch].item() for a in batch['original_resolution']]\n",
    "\n",
    "        # Get coarse output from deeplab model from 256 resolution input\n",
    "        out_coarse = deeplab(image_1)\n",
    "        out_coarse = out_coarse.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "        bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "        bv_coarse = bv_coarse.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "        #bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "        \n",
    "        bbox_concat = torch.cat([bbox_image, bbox_bv], dim=1)\n",
    "        \n",
    "        #show_image_slice(label_1)\n",
    "        #show_image_slice(bv_label)\n",
    "        #show_image_slice(bbox_image)\n",
    "        #show_image_slice(bbox_label)\n",
    "        #show_image_slice(bbox_bv)\n",
    "\n",
    "        #print(\"bbox_concat\", bbox_concat.shape)\n",
    "\n",
    "        del out_coarse\n",
    "        del image_1\n",
    "        del bv_coarse\n",
    "        del label_1\n",
    "        del bv_label\n",
    "        del bbox_image\n",
    "        del bbox_bv\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        refine_out = refine_model(bbox_concat)\n",
    "        # do the inference\n",
    "\n",
    "        #print(refine_out.shape)\n",
    "        #print(bbox_bv_label.shape)\n",
    "\n",
    "        loss = dice_loss(refine_out, bbox_label)\n",
    "        \n",
    "        print(loss)\n",
    "        epoch_loss += loss.item()\n",
    "        # record minibatch loss to epoch loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # set the model parameter gradient to zero\n",
    "        \n",
    "        loss.backward()\n",
    "        # calculate the gradient wrt loss\n",
    "        optimizer.step()\n",
    "        # take a gradient descent step\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    outstr = 'Epoch {0} finished ! Training Loss: {1:.4f}'.format(e, epoch_loss/(t+1)) + '\\n'\n",
    "    \n",
    "    logger['train'].append(epoch_loss/(t+1))\n",
    "    \n",
    "    print(outstr)\n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "\n",
    "    if e%2 == 0:\n",
    "    # do validation every 5 epoches\n",
    "        deeplab.eval()\n",
    "        refine_model.eval()\n",
    "        # set model flag to eval\n",
    "        # 1. disable dropout\n",
    "        # 2. batchnorm behave differs\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # stop taking gradient\n",
    "        \n",
    "            #valloss_4 = 0\n",
    "            #valloss_2 = 0\n",
    "            valloss_1 = 0\n",
    "            \n",
    "            for v, vbatch in enumerate(validation_loader):\n",
    "                image_1 = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "                image_1 = image_1.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                label_1 = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "                label_1 = label_1.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "                bv_label = label_1[:, 2, :, :, :]\n",
    "                bv_label = bv_label.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                #original_res = [a[minibatch].item() for a in batch['original_resolution']]\n",
    "\n",
    "                # Get coarse output from deeplab model from 256 resolution input\n",
    "                out_coarse = deeplab(image_1)\n",
    "                out_coarse = out_coarse.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "                bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "                bv_coarse = bv_coarse.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "\n",
    "                bbox_concat = torch.cat([bbox_image, bbox_bv], dim=1)\n",
    "\n",
    "                #show_image_slice(label)\n",
    "                #show_image_slice(bbox_image)\n",
    "                #show_image_slice(bbox_label)\n",
    "                #show_image_slice(bbox_bv)\n",
    "\n",
    "                #print(\"bbox_concat\", bbox_concat.shape)\n",
    "                #seg_image_concat = torch.cat([bv_coarse, image_1], dim=1)\n",
    "\n",
    "                del out_coarse\n",
    "                del image_1\n",
    "                del bv_coarse\n",
    "                del label_1\n",
    "                del bv_label\n",
    "                del bbox_image\n",
    "                del bbox_bv\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                refine_out = refine_model(bbox_concat)\n",
    "                        \n",
    "                loss = dice_loss(refine_out, bbox_label)\n",
    "                \n",
    "                print(loss)\n",
    "            \n",
    "                # calculate loss\n",
    "                valloss_1 += loss.item()\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            \n",
    "            avg_val_loss = (valloss_1 / (v+1))\n",
    "            outstr = '------- 1st valloss={0:.4f}'\\\n",
    "                .format(avg_val_loss) + '\\n'\n",
    "            \n",
    "            logger['validation_1'].append(avg_val_loss)\n",
    "            #scheduler.step(avg_val_loss)\n",
    "            \n",
    "            if avg_val_loss < min_val:\n",
    "                save_1('refine_bv5_save', refine_model, optimizer, logger, e, scheduler)\n",
    "            elif e % 10 == 0:\n",
    "                save_1('refine_bv5_save', refine_model, optimizer, logger, e, scheduler)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            print(outstr)\n",
    "            record.write(outstr)\n",
    "            record.flush()\n",
    "    \n",
    "\n",
    "\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_1_resize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_slice(image_1)\n",
    "show_image_slice(label_1)\n",
    "show_image_slice(bbox_bv_label)\n",
    "show_image_slice(out_coarse)\n",
    "show_image_slice(bbox_bv)\n",
    "show_image_slice(bbox_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = loadbvcenter(image_1.squeeze(0).cpu().detach().numpy())\n",
    "x1 = int(b[0])\n",
    "y1 = int(b[1])\n",
    "z1 = int(b[2])\n",
    "show_image_slice(bv_label[x1-64:x1+64, y1-64:y1+64, z1-64:z1+64])\n",
    "c = find_bv_centroid(bv_label)\n",
    "x2 = int(c[0])\n",
    "y2 = int(c[1])\n",
    "z2 = int(c[2])\n",
    "show_image_slice(bv_label[x2-64:x2+64, y2-64:y2+64, z2-64:z2+64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bv_coarse.shape)\n",
    "print(\"bbox_bv_label\", bbox_bv_label.shape)\n",
    "print(\"bbox_bv\", bbox_bv.shape)\n",
    "print(\"bbox_image\", bbox_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    bgloss = 0\n",
    "    bdloss = 0\n",
    "    bvloss = 0\n",
    "    \n",
    "    for v, vbatch in tqdm(enumerate(validation_loader)):\n",
    "        # move data to device, convert dtype to desirable dtype\n",
    "        image_1 = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "\n",
    "        output = deeplab(image_1)\n",
    "        # do the inference\n",
    "        output_numpy = output.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        #out_1 = torch.round(output)\n",
    "        out_1 = torch.from_numpy((output_numpy == output_numpy.max(axis=1)[:, None]).astype(int)).to(device=device, dtype=dtype)\n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "\n",
    "        bg, bd, bv = dice_loss_3_debug(out_1, label_1)\n",
    "        # calculate loss\n",
    "        print(bg.item(), bd.item(), bv.item(), loss_1.item())\n",
    "        bgloss += bg.item()\n",
    "        bdloss += bd.item()\n",
    "        bvloss += bv.item()\n",
    "        \n",
    "        if bv.item() >= 0.2 or bd.item() >= 0.1:\n",
    "            show_image_slice(image_1)\n",
    "            show_image_slice(label_1)\n",
    "            show_image_slice(output)\n",
    "\n",
    "    outstr = '------- background loss = {0:.4f}, body loss = {1:.4f}, bv loss = {2:.4f}'\\\n",
    "        .format(bgloss/(v+1), bdloss/(v+1), bvloss/(v+1)) + '\\n'\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
