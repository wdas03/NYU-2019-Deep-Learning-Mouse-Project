{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utility import *\n",
    "from data_utils import *\n",
    "from loss import *\n",
    "from train import *\n",
    "from deeplab_model.deeplab import *\n",
    "from dense_vnet.DenseVNet import DenseVNet\n",
    "from sync_batchnorm import convert_model\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "NUM_WORKERS = 12\n",
    "BATCH_SIZE = 2 \n",
    "\n",
    "dtype = torch.float32 \n",
    "# define dtype, float is space efficient than double\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # magic flag that accelerate\n",
    "    \n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_full_resolution_dataset(data_type = 'nii_train', \n",
    "                transform=transforms.Compose([\n",
    "                random_affine(90, 15),\n",
    "                random_filp(0.5)]))\n",
    "# do data augumentation on train dataset\n",
    "\n",
    "validation_dataset = get_full_resolution_dataset(data_type = 'nii_test', \n",
    "                transform=None)\n",
    "# no data augumentation on validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS) # drop_last\n",
    "# loaders come with auto batch division and multi-thread acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from vnet import VNet\n",
    "from bv_refinement_network.RefinementModel import RefinementModel_ELU\n",
    "from refinenet import refine_net\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    \n",
    "#checkpoint_refine = torch.load('../refine_bv_resize_save/2019-08-22 00:10:23.854113 epoch: 41.pth')\n",
    "    \n",
    "refine_model = VNet(classnum=1, in_channels=1)\n",
    "#refine_model = nn.DataParallel(refine_model)\n",
    "#refine_model = convert_model(refine_model)\n",
    "\n",
    "#refine_model.load_state_dict(checkpoint_refine['state_dict_1'])\n",
    "\n",
    "refine_model = refine_model.to(device, dtype)\n",
    "\n",
    "optimizer = optim.Adam(refine_model.parameters(), lr=1e-2)\n",
    "#optimizer.load_state_dict(checkpoint_refine['optimizer'])\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "#scheduler.load_state_dict(checkpoint_refine['scheduler'])\n",
    "\n",
    "deeplab = DeepLab(output_stride=16)\n",
    "deeplab = nn.DataParallel(deeplab)\n",
    "deeplab = convert_model(deeplab)\n",
    "\n",
    "checkpoint = torch.load('../deeplab_dilated_save/2019-08-10 09:28:43.844872 epoch: 1160.pth') # best one\n",
    "\n",
    "deeplab.load_state_dict(checkpoint['state_dict_1'])\n",
    "deeplab = deeplab.to(device, dtype)\n",
    "\n",
    "epoch = 0\n",
    "#epoch = 0\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(image, label, output, batchsize, box_size):\n",
    "    image_final = torch.zeros((batchsize, 1, box_size, box_size, box_size)).to(device, dtype)\n",
    "    label_final = torch.zeros((batchsize, 1, box_size, box_size, box_size)).to(device, dtype)\n",
    "    output_final = torch.zeros((batchsize, 1, box_size, box_size, box_size)).to(device, dtype)\n",
    "    half_size = int(box_size/2)\n",
    "    image_size_x = int(image.shape[-3])\n",
    "    image_size_y = int(image.shape[-2])\n",
    "    image_size_z = int(image.shape[-1])\n",
    "    for b in range(batchsize):\n",
    "        out = output[b]\n",
    "        x,y,z = loadbvcenter(binarize_output(out))\n",
    "        x, y, z = np.clip([x, y, z], a_min=half_size, a_max=181)\n",
    "        x1 = max(x-half_size, 0)\n",
    "        x2 = min(x+half_size, image_size_x)\n",
    "        y1 = max(y-half_size, 0)\n",
    "        y2 = min(y+half_size, image_size_y)\n",
    "        z1 = max(z-half_size, 0)\n",
    "        z2 = min(z+half_size, image_size_z)\n",
    "        image_final[b] = image[b, :, x1:x2, y1:y2, z1:z2]\n",
    "        label_final[b] = label[b, :, x1:x2, y1:y2, z1:z2]\n",
    "        output_final[b] = output[b, :, x1:x2, y1:y2, z1:z2]\n",
    "    return image_final, label_final, output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9900, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 15.75 GiB total capacity; 14.69 GiB already allocated; 40.12 MiB free; 42.38 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0090870ff6df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Get coarse output from deeplab model from 256 resolution input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mout_coarse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeeplab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mout_coarse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_coarse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/whd226/semantic-segmentation-ub/src/deeplab_model/deeplab.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maspp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_level_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'trilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/whd226/semantic-segmentation-ub/src/deeplab_model/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, low_level_feat)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#print('x', x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlow_level_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'trilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;31m#x = self.transpose(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners)\u001b[0m\n\u001b[1;32m   2569\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got 5D input, but bilinear mode needs 4D input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trilinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2571\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_trilinear3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_output_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2572\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bicubic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2573\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_bicubic2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_output_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 15.75 GiB total capacity; 14.69 GiB already allocated; 40.12 MiB free; 42.38 MiB cached)"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "record = open('train_bv_refine_resize_no_concat_vnet.txt','a+')\n",
    "\n",
    "logger = {'train':[], 'validation_1': []}\n",
    "\n",
    "min_val = 1\n",
    "\n",
    "for e in tqdm(range(epoch + 1, epochs)):\n",
    "# iter over epoches\n",
    "    epoch_loss = 0\n",
    "        \n",
    "    for t, batch in enumerate(train_loader):\n",
    "    # iter over the train mini batches\n",
    "        train_losses=[]\n",
    "        for minibatch in range(BATCH_SIZE):\n",
    "            refine_model.train()\n",
    "            deeplab.eval()\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            # Set the model flag to train\n",
    "            # 1. enable dropout\n",
    "            # 2. batchnorm behave differently in train and test\n",
    "            #print(batch['image1_data'])\n",
    "            image_1 = batch['image1_data'][minibatch].to(device=device, dtype=dtype)\n",
    "            image_1 = image_1.view(1,1,256,256,256)\n",
    "\n",
    "            label_1 = batch['image1_label'][minibatch].to(device=device, dtype=dtype)\n",
    "            label_1 = label_1.view(1,3,256,256,256)\n",
    "\n",
    "            bv_label = label_1[:, 2, :, :, :]\n",
    "            bv_label = bv_label.view(1,1,256,256,256)\n",
    "\n",
    "            original_res = [a[minibatch].item() for a in batch['original_resolution']]\n",
    "\n",
    "            image_1_resize = F.interpolate(image_1, size=original_res, mode='trilinear', align_corners=True)\n",
    "            image_1_resize = image_1_resize.view(1,1,original_res[0], original_res[1], original_res[2])\n",
    "\n",
    "            bv_label_resize = F.interpolate(bv_label, size=original_res, mode='trilinear', align_corners=True)\n",
    "\n",
    "            # Get coarse output from deeplab model from 256 resolution input\n",
    "            out_coarse = deeplab(image_1)\n",
    "            out_coarse = out_coarse.view(1,3,256,256,256)\n",
    "            \n",
    "            bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "            bv_coarse = bv_coarse.view(1,1,256,256,256)\n",
    "            \n",
    "            del out_coarse\n",
    "            \n",
    "            bv_coarse_resize = F.interpolate(bv_coarse, size=original_res, mode='trilinear', align_corners=True)\n",
    "\n",
    "            del bv_coarse\n",
    "\n",
    "            box_size = 192\n",
    "            half_size = int(box_size / 2)\n",
    "\n",
    "            image_size_x = int(image_1_resize.shape[-3])\n",
    "            image_size_y = int(image_1_resize.shape[-2])\n",
    "            image_size_z = int(image_1_resize.shape[-1])\n",
    "\n",
    "            x,y,z = loadbvcenter(binarize_output(bv_coarse_resize).view([1] + original_res))\n",
    "            x, y, z = np.clip([x, y, z], a_min=box_size-half_size, a_max=box_size+half_size)\n",
    "            x1 = max(x-half_size, 0)\n",
    "            x2 = min(x+half_size, image_size_x)\n",
    "            y1 = max(y-half_size, 0)\n",
    "            y2 = min(y+half_size, image_size_y)\n",
    "            z1 = max(z-half_size, 0)\n",
    "            z2 = min(z+half_size, image_size_z)\n",
    "\n",
    "            bbox_bv = bv_coarse_resize.view(original_res)[x1:x2, y1:y2, z1:z2]\n",
    "            bbox_bv = reshape_image(bbox_bv.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "            bbox_bv = bbox_bv.view(1,1,box_size,box_size,box_size)\n",
    "\n",
    "            del bv_coarse_resize\n",
    "\n",
    "            bbox_bv_label = bv_label_resize.view(original_res)[x1:x2, y1:y2, z1:z2]\n",
    "            bbox_bv_label = reshape_image(bbox_bv_label.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "            bbox_bv_label = bbox_bv_label.view(1,1,box_size,box_size,box_size)\n",
    "\n",
    "            del bv_label_resize\n",
    "\n",
    "            bbox_image = image_1_resize[:, :, x1:x2, y1:y2, z1:z2]\n",
    "            bbox_image = reshape_image(bbox_image.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "            bbox_image = bbox_image.view(1, 1, box_size, box_size, box_size)\n",
    "\n",
    "            del image_1_resize\n",
    "\n",
    "            refine_out = refine_model(bbox_image)\n",
    "\n",
    "            del bbox_image\n",
    "\n",
    "            loss = dice_loss(refine_out, bbox_bv_label)\n",
    "\n",
    "            del refine_out\n",
    "            del bbox_bv_label\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            print(loss)\n",
    "            train_losses.append(loss)\n",
    "        \n",
    "        loss = sum(train_losses) / BATCH_SIZE\n",
    "        train_losses=[]\n",
    "        epoch_loss += loss.item()\n",
    "        # record minibatch loss to epoch loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # set the model parameter gradient to zero\n",
    "        \n",
    "        loss.backward()\n",
    "        # calculate the gradient wrt loss\n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss_1)\n",
    "        # take a gradient descent step\n",
    "        \n",
    "    outstr = 'Epoch {0} finished ! Training Loss: {1:.4f}'.format(e, epoch_loss/(t+1)) + '\\n'\n",
    "    \n",
    "    logger['train'].append(epoch_loss/(t+1))\n",
    "    \n",
    "    print(outstr)\n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "\n",
    "    if e%1 == 0:\n",
    "    # do validation every 5 epoches\n",
    "        deeplab.eval()\n",
    "        refine_model.eval()\n",
    "        # set model flag to eval\n",
    "        # 1. disable dropout\n",
    "        # 2. batchnorm behave differs\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # stop taking gradient\n",
    "        \n",
    "            #valloss_4 = 0\n",
    "            #valloss_2 = 0\n",
    "            valloss_1 = 0\n",
    "            \n",
    "            for v, vbatch in enumerate(validation_loader):\n",
    "            # iter over validation mini batches\n",
    "                val_losses = []\n",
    "                for minibatch in range(BATCH_SIZE):\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    image_1 = vbatch['image1_data'][minibatch].to(device=device, dtype=dtype)\n",
    "                    image_1 = image_1.view(1,1,256,256,256)\n",
    "\n",
    "                    label_1 = vbatch['image1_label'][minibatch].to(device=device, dtype=dtype)\n",
    "                    label_1 = label_1.view(1,3,256,256,256)\n",
    "\n",
    "                    bv_label = label_1[:, 2, :, :, :]\n",
    "                    bv_label = bv_label.view(1,1,256,256,256)\n",
    "\n",
    "                    original_res = [a[minibatch].item() for a in vbatch['original_resolution']]\n",
    "\n",
    "                    image_1_resize = F.interpolate(image_1, size=original_res, mode='trilinear', align_corners=True)\n",
    "                    image_1_resize = image_1_resize.view(1,1,original_res[0], original_res[1], original_res[2])\n",
    "\n",
    "                    bv_label_resize = F.interpolate(bv_label, size=original_res, mode='trilinear', align_corners=True)\n",
    "\n",
    "                    # Get coarse output from deeplab model from 256 resolution input\n",
    "                    out_coarse = deeplab(image_1)\n",
    "                    out_coarse = out_coarse.view(1,3,256,256,256)\n",
    "\n",
    "                    bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "                    bv_coarse = bv_coarse.view(1,1,256,256,256)\n",
    "                    \n",
    "                    del out_coarse\n",
    "\n",
    "                    bv_coarse_resize = F.interpolate(bv_coarse, size=original_res, mode='trilinear', align_corners=True)\n",
    "                    \n",
    "                    del bv_coarse\n",
    "                    \n",
    "                    box_size = 192\n",
    "                    half_size = int(box_size / 2)\n",
    "\n",
    "                    image_size_x = int(image_1_resize.shape[-3])\n",
    "                    image_size_y = int(image_1_resize.shape[-2])\n",
    "                    image_size_z = int(image_1_resize.shape[-1])\n",
    "\n",
    "                    x,y,z = loadbvcenter(binarize_output(bv_coarse_resize).view([1] + original_res))\n",
    "                    x, y, z = np.clip([x, y, z], a_min=box_size-half_size, a_max=box_size+half_size)\n",
    "                    x1 = max(x-half_size, 0)\n",
    "                    x2 = min(x+half_size, image_size_x)\n",
    "                    y1 = max(y-half_size, 0)\n",
    "                    y2 = min(y+half_size, image_size_y)\n",
    "                    z1 = max(z-half_size, 0)\n",
    "                    z2 = min(z+half_size, image_size_z)\n",
    "\n",
    "                    bbox_bv = bv_coarse_resize.view(original_res)[x1:x2, y1:y2, z1:z2]\n",
    "                    bbox_bv = reshape_image(bbox_bv.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "                    bbox_bv = bbox_bv.view(1,1,box_size,box_size,box_size)\n",
    "                    \n",
    "                    del bv_coarse_resize\n",
    "                    \n",
    "                    bbox_bv_label = bv_label_resize.view(original_res)[x1:x2, y1:y2, z1:z2]\n",
    "                    bbox_bv_label = reshape_image(bbox_bv_label.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "                    bbox_bv_label = bbox_bv_label.view(1,1,box_size,box_size,box_size)\n",
    "\n",
    "                    del bv_label_resize\n",
    "                    \n",
    "                    bbox_image = image_1_resize[:, :, x1:x2, y1:y2, z1:z2]\n",
    "                    bbox_image = reshape_image(bbox_image.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "                    bbox_image = bbox_image.view(1, 1, box_size, box_size, box_size)\n",
    "                    \n",
    "                    del image_1_resize\n",
    "                    \n",
    "                    refine_out = refine_model(bbox_image)\n",
    "                    \n",
    "                    del bbox_image\n",
    "                    del bbox_image_2\n",
    "                    del bbox_image_4\n",
    "                    \n",
    "                    loss = dice_loss(refine_out, bbox_bv_label)\n",
    "                    \n",
    "                    del refine_out\n",
    "                    del bbox_bv_label\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    val_losses.append(loss)\n",
    "                \n",
    "                avg_loss = sum(val_losses) / BATCH_SIZE\n",
    "                val_losses = []\n",
    "                print(avg_loss)\n",
    "            \n",
    "                # calculate loss\n",
    "                valloss_1 += avg_loss.item()\n",
    "                \n",
    "            \n",
    "            avg_val_loss = (valloss_1 / (v+1))\n",
    "            outstr = '------- 1st valloss={0:.4f}'\\\n",
    "                .format(avg_val_loss) + '\\n'\n",
    "            \n",
    "            logger['validation_1'].append(avg_val_loss)\n",
    "            #scheduler.step(avg_val_loss)\n",
    "            \n",
    "            if avg_val_loss < min_val:\n",
    "                min_val = avg_val_loss\n",
    "                save_1('refine_bv_resize_no_concat_2_vnet_save', refine_model, optimizer, logger, e, scheduler)\n",
    "            elif e % 10 == 0:\n",
    "                save_1('refine_bv_resize_no_concat_2_vnet_save', refine_model, optimizer, logger, e, scheduler)\n",
    "            \n",
    "            print(outstr)\n",
    "            record.write(outstr)\n",
    "            record.flush()\n",
    "    \n",
    "\n",
    "\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab.eval()\n",
    "refine_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    val_loss = 0\n",
    "    \n",
    "    for v, vbatch in tqdm(enumerate(validation_loader)):\n",
    "        # move data to device, convert dtype to desirable dtype\n",
    "        val_losses = []\n",
    "        for minibatch in range(BATCH_SIZE):\n",
    "            image_1 = vbatch['image1_data'][minibatch].to(device=device, dtype=dtype)\n",
    "            image_1 = image_1.view(1,1,256,256,256)\n",
    "\n",
    "            label_1 = vbatch['image1_label'][minibatch].to(device=device, dtype=dtype)\n",
    "            label_1 = label_1.view(1,3,256,256,256)\n",
    "\n",
    "            bv_label = label_1[:, 2, :, :, :]\n",
    "            bv_label = bv_label.view(1,1,256,256,256)\n",
    "\n",
    "            original_res = [a[minibatch].item() for a in vbatch['original_resolution']]\n",
    "\n",
    "            image_1_resize = F.interpolate(image_1, size=original_res, mode='trilinear', align_corners=True)\n",
    "            image_1_resize = image_1_resize.view(1,1,original_res[0], original_res[1], original_res[2])\n",
    "\n",
    "            bv_label_resize = F.interpolate(bv_label, size=original_res, mode='trilinear', align_corners=True)\n",
    "\n",
    "            # Get coarse output from deeplab model from 256 resolution input\n",
    "            out_coarse = deeplab(image_1)\n",
    "            out_coarse = out_coarse.view(1,3,256,256,256)\n",
    "\n",
    "            bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "            bv_coarse = bv_coarse.view(1,1,256,256,256)\n",
    "\n",
    "            bv_coarse_resize = F.interpolate(bv_coarse, size=original_res, mode='trilinear', align_corners=True)\n",
    "            \n",
    "            box_size = 192\n",
    "            half_size = int(box_size / 2)\n",
    "            \n",
    "            image_size_x = int(image_1_resize.shape[-3])\n",
    "            image_size_y = int(image_1_resize.shape[-2])\n",
    "            image_size_z = int(image_1_resize.shape[-1])\n",
    "            \n",
    "            x,y,z = loadbvcenter(binarize_output(bv_coarse_resize).view([1] + original_res))\n",
    "            x, y, z = np.clip([x, y, z], a_min=box_size-half_size, a_max=box_size+half_size)\n",
    "            x1 = max(x-half_size, 0)\n",
    "            x2 = min(x+half_size, image_size_x)\n",
    "            y1 = max(y-half_size, 0)\n",
    "            y2 = min(y+half_size, image_size_y)\n",
    "            z1 = max(z-half_size, 0)\n",
    "            z2 = min(z+half_size, image_size_z)\n",
    "            \n",
    "            \n",
    "            bbox_bv = bv_coarse_resize.view(original_res)[x1:x2, y1:y2, z1:z2]\n",
    "            bbox_bv = reshape_image(bbox_bv.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "            bbox_bv = bbox_bv.view(1,1,box_size,box_size,box_size)\n",
    "            \n",
    "            bbox_bv_label = bv_label_resize.view(original_res)[x1:x2, y1:y2, z1:z2]\n",
    "            bbox_bv_label = reshape_image(bbox_bv_label.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "            bbox_bv_label = bbox_bv_label.view(1,1,box_size,box_size,box_size)\n",
    "\n",
    "            #bbox_image = get_bounding_box_image(image_1, (256,256,256)).to(device, dtype)\n",
    "            bbox_image = image_1_resize[:, :, x1:x2, y1:y2, z1:z2]\n",
    "            bbox_image = reshape_image(bbox_image.squeeze(), box_size, box_size, box_size).to(device, dtype)\n",
    "            bbox_image = bbox_image.view(1, 1, box_size, box_size, box_size)\n",
    "            \n",
    "            #bbox_iamge, bbox_bv_label, bbox_bv = get_bboxes(image_1_resize, bv_label_resize, bv_coarse_resize, 1, 200)\n",
    "            \n",
    "            bbox_concat = torch.cat([bbox_bv, bbox_image], dim=1)\n",
    "            bbox_concat_2 = F.interpolate(bbox_concat, scale_factor=1/2, mode='trilinear', align_corners=True)\n",
    "            bbox_concat_4 = F.interpolate(bbox_concat, scale_factor=1/4, mode='trilinear', align_corners=True)\n",
    "\n",
    "            refine_out = refine_model(bbox_concat, bbox_concat_2, bbox_concat_4)\n",
    "\n",
    "            loss = dice_loss(refine_out, bbox_bv_label)\n",
    "            val_losses.append(loss)\n",
    "            \n",
    "            if loss.item() > .04:\n",
    "                show_image_slice(image_1)\n",
    "                show_image_slice(bv_label_resize)\n",
    "                show_image_slice(bv_coarse)\n",
    "                show_image_slice(bbox_image)\n",
    "                show_image_slice(bbox_bv_label)\n",
    "                show_image_slice(bbox_bv)\n",
    "                show_image_slice(refine_out)\n",
    "        \n",
    "        loss = sum(val_losses) / BATCH_SIZE\n",
    "        print(loss.item())\n",
    "        val_loss += loss.item()\n",
    "        val_losses = []\n",
    "        '''\n",
    "        if loss.item() > .05:\n",
    "            show_image_slice(image_1)\n",
    "            show_image_slice(label_1)\n",
    "            show_image_slice(output)\n",
    "        '''\n",
    "\n",
    "    outstr = 'bv loss = {0:.4f}'\\\n",
    "        .format(val_loss/(v+1)) + '\\n'\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
