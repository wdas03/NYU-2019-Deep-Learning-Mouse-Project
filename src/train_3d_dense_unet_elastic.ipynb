{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utility import *\n",
    "from data_utils import get_dimensions\n",
    "from loss import *\n",
    "from train import *\n",
    "from sync_batchnorm import convert_model\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "NUM_WORKERS = 12\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "dtype = torch.float32 \n",
    "# define dtype, float is space efficient than double\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # magic flag that accelerate\n",
    "    \n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pyramid_dataset(data_type = 'nii_train', \n",
    "                transform=transforms.Compose([\n",
    "                random_affine(90, 15),\n",
    "                random_filp(0.5), \n",
    "                transforms.RandomApply([ElasticTransformation(256*2, 256*0.08)])\n",
    "                ]))\n",
    "# do data augumentation on train dataset\n",
    "\n",
    "validation_dataset = pyramid_dataset(data_type = 'nii_test', transform=None)\n",
    "# no data augumentation on validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "# loaders come with auto batch division and multi-thread acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv3d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "    elif isinstance(m, nn.BatchNorm3d):\n",
    "        init.normal_(m.weight.data, mean=0, std=1)\n",
    "\n",
    "def downsample_label(label, scale_factor):\n",
    "    return F.interpolate(label, scale_factor=scale_factor, mode='trilinear', align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_test(model, cuda_bool):\n",
    "    x = torch.zeros((1, 1, 256, 256, 256))\n",
    "    x = x.to(device=device, dtype=dtype) if cuda_bool else x\n",
    "    model = model.to(device=device, dtype=dtype) if cuda_bool else model\n",
    "    scores = model(x)\n",
    "    for i in scores:\n",
    "        print(i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest_dictionary = train_dataset[33]\\n\\nimage_1 = test_dictionary['image1_data'].view(1, 1, 256, 256, 256).to(device=device, dtype=dtype)\\nlabel_1 = test_dictionary['image1_label'].view(1, 3, 256, 256, 256).to(device=device, dtype=dtype)\\n\\n#image_2 = test_dictionary['image2_data'].view(1, 1, 128, 128, 128).to(device=device, dtype=dtype)\\n#label_2 = test_dictionary['image2_label'].view(1, 3, 128, 128, 128).to(device=device, dtype=dtype)\\n\\n#label_2_resize_2 = downsample_label(label_2, 1/2).to(device=device, dtype=dtype)\\n\\nfrom dense_unet_3d import Model\\n\\nm = Model()\\n#m = nn.DataParallel(m)\\n#m = convert_model(m)\\nm.apply(init_weights)\\nm = m.to(device=device, dtype=dtype)\\n#shape_test(m, True)\\n\\noptimizer = optim.Adam(m.parameters(), lr=1e-3)\\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\\nepoch=0\\n#shape_test(m, True)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_dictionary = train_dataset[33]\n",
    "\n",
    "image_1 = test_dictionary['image1_data'].view(1, 1, 256, 256, 256).to(device=device, dtype=dtype)\n",
    "label_1 = test_dictionary['image1_label'].view(1, 3, 256, 256, 256).to(device=device, dtype=dtype)\n",
    "\n",
    "#image_2 = test_dictionary['image2_data'].view(1, 1, 128, 128, 128).to(device=device, dtype=dtype)\n",
    "#label_2 = test_dictionary['image2_label'].view(1, 3, 128, 128, 128).to(device=device, dtype=dtype)\n",
    "\n",
    "#label_2_resize_2 = downsample_label(label_2, 1/2).to(device=device, dtype=dtype)\n",
    "\n",
    "from dense_unet_3d import Model\n",
    "\n",
    "m = Model()\n",
    "#m = nn.DataParallel(m)\n",
    "#m = convert_model(m)\n",
    "m.apply(init_weights)\n",
    "m = m.to(device=device, dtype=dtype)\n",
    "#shape_test(m, True)\n",
    "\n",
    "optimizer = optim.Adam(m.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "epoch=0\n",
    "#shape_test(m, True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "from dense_unet_3d import Model\n",
    "m = Model()\n",
    "optimizer = optim.Adam(m.parameters())\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "checkpoint = torch.load('../3d_dense_unet_elastic_save/2019-08-05 12:11:38.146979 epoch: 75.pth')\n",
    "m.load_state_dict(checkpoint['state_dict_1'])\n",
    "m = m.to(device, dtype)\n",
    "\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4924 [14:01<1151:19:38, 841.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 finished ! Training Loss: 0.1968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/4924 [25:44<1093:45:46, 799.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 finished ! Training Loss: 0.1931\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/4924 [37:37<1058:05:39, 774.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 finished ! Training Loss: 0.2185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/4924 [49:27<1031:39:34, 754.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 finished ! Training Loss: 0.1996\n",
      "\n",
      "Epoch 80 finished ! Training Loss: 0.1969\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/4924 [1:02:05<1032:32:05, 755.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.2117\n",
      "\n",
      "Checkpoint 80 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/4924 [1:13:53<1013:00:57, 741.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 finished ! Training Loss: 0.1955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/4924 [1:25:44<1000:22:49, 732.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 finished ! Training Loss: 0.1935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/4924 [1:37:31<989:30:34, 724.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 finished ! Training Loss: 0.2046\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/4924 [1:49:25<984:58:49, 721.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 finished ! Training Loss: 0.1827\n",
      "\n",
      "Epoch 85 finished ! Training Loss: 0.2011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/4924 [2:02:15<1004:51:42, 736.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.2474\n",
      "\n",
      "Checkpoint 85 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 11/4924 [2:14:04<993:26:08, 727.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 finished ! Training Loss: 0.1979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 12/4924 [2:26:02<988:57:29, 724.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 finished ! Training Loss: 0.1898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 13/4924 [2:37:56<984:20:50, 721.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 finished ! Training Loss: 0.1946\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 14/4924 [2:49:50<981:20:51, 719.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 finished ! Training Loss: 0.1989\n",
      "\n",
      "Epoch 90 finished ! Training Loss: 0.1978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 15/4924 [3:02:39<1001:23:09, 734.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.1374\n",
      "\n",
      "Checkpoint 90 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 16/4924 [3:14:27<990:22:20, 726.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 finished ! Training Loss: 0.1832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 17/4924 [3:26:12<981:15:15, 719.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 finished ! Training Loss: 0.1965\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 18/4924 [3:37:56<974:25:37, 715.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 finished ! Training Loss: 0.1749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 19/4924 [3:49:50<973:45:36, 714.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 finished ! Training Loss: 0.2083\n",
      "\n",
      "Epoch 95 finished ! Training Loss: 0.1892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 20/4924 [4:02:34<993:50:42, 729.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.1623\n",
      "\n",
      "Checkpoint 95 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 21/4924 [4:14:25<986:17:21, 724.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 finished ! Training Loss: 0.1765\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 22/4924 [4:26:21<982:22:39, 721.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 finished ! Training Loss: 0.1940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 23/4924 [4:38:10<977:13:08, 717.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 finished ! Training Loss: 0.2191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 24/4924 [4:49:54<971:15:56, 713.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 finished ! Training Loss: 0.1879\n",
      "\n",
      "Epoch 100 finished ! Training Loss: 0.1951\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 25/4924 [5:02:32<989:31:04, 727.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.4101\n",
      "\n",
      "Checkpoint 100 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 26/4924 [5:14:16<979:48:07, 720.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 finished ! Training Loss: 0.1972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 27/4924 [5:26:05<975:01:11, 716.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 finished ! Training Loss: 0.2005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 28/4924 [5:37:58<973:25:00, 715.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 finished ! Training Loss: 0.2110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 29/4924 [5:49:53<972:45:18, 715.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 finished ! Training Loss: 0.1804\n",
      "\n",
      "Epoch 105 finished ! Training Loss: 0.1813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 30/4924 [6:02:36<991:53:27, 729.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.1729\n",
      "\n",
      "Checkpoint 105 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 31/4924 [6:14:25<983:08:55, 723.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 finished ! Training Loss: 0.1871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 32/4924 [6:26:12<976:35:01, 718.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 finished ! Training Loss: 0.1793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 33/4924 [6:38:03<973:02:16, 716.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 finished ! Training Loss: 0.1968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 34/4924 [6:49:57<972:13:10, 715.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 finished ! Training Loss: 0.1833\n",
      "\n",
      "Epoch 110 finished ! Training Loss: 0.1934\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 35/4924 [7:02:39<990:45:20, 729.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.1810\n",
      "\n",
      "Checkpoint 110 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 36/4924 [7:14:23<979:58:32, 721.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 finished ! Training Loss: 0.1815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 37/4924 [7:26:13<975:08:55, 718.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 finished ! Training Loss: 0.1917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 38/4924 [7:38:03<971:18:15, 715.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 finished ! Training Loss: 0.1891\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 39/4924 [7:49:53<969:03:33, 714.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 finished ! Training Loss: 0.1696\n",
      "\n",
      "Epoch 115 finished ! Training Loss: 0.1901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 40/4924 [8:02:33<987:25:07, 727.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.3829\n",
      "\n",
      "Checkpoint 115 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 41/4924 [8:14:25<980:40:50, 723.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 finished ! Training Loss: 0.1687\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 42/4924 [8:26:07<972:11:03, 716.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 finished ! Training Loss: 0.1684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 43/4924 [8:38:04<971:48:47, 716.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 finished ! Training Loss: 0.1977\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 44/4924 [8:49:55<969:28:27, 715.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 finished ! Training Loss: 0.1866\n",
      "\n",
      "Epoch 120 finished ! Training Loss: 0.2015\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 45/4924 [9:02:45<991:24:29, 731.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.2168\n",
      "\n",
      "Checkpoint 120 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 46/4924 [9:14:43<985:43:17, 727.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 finished ! Training Loss: 0.1917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 47/4924 [9:26:28<976:14:10, 720.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 finished ! Training Loss: 0.1923\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 48/4924 [9:38:20<972:41:27, 718.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 finished ! Training Loss: 0.1977\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 49/4924 [9:50:15<971:18:16, 717.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 finished ! Training Loss: 0.1996\n",
      "\n",
      "Epoch 125 finished ! Training Loss: 0.2010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 50/4924 [10:02:52<987:16:50, 729.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.2244\n",
      "\n",
      "Checkpoint 125 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 51/4924 [10:14:44<979:51:30, 723.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 finished ! Training Loss: 0.1702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 52/4924 [10:26:36<975:00:24, 720.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 finished ! Training Loss: 0.2073\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 53/4924 [10:38:29<971:46:42, 718.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 finished ! Training Loss: 0.1867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 54/4924 [10:50:20<968:41:04, 716.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 finished ! Training Loss: 0.1906\n",
      "\n",
      "Epoch 130 finished ! Training Loss: 0.1786\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 55/4924 [11:03:01<986:34:26, 729.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.1440\n",
      "\n",
      "Checkpoint 130 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 56/4924 [11:15:02<982:53:32, 726.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 finished ! Training Loss: 0.1872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 57/4924 [11:26:57<978:00:22, 723.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 finished ! Training Loss: 0.1849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 58/4924 [11:38:44<971:02:56, 718.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133 finished ! Training Loss: 0.1942\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 59/4924 [11:50:39<969:39:55, 717.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 finished ! Training Loss: 0.1768\n",
      "\n",
      "Epoch 135 finished ! Training Loss: 0.1838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 60/4924 [12:03:18<986:18:50, 730.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.3030\n",
      "\n",
      "Checkpoint 135 saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 61/4924 [12:15:11<979:07:21, 724.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 finished ! Training Loss: 0.1838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 62/4924 [12:27:07<975:15:00, 722.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 finished ! Training Loss: 0.1732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 63/4924 [12:38:59<970:53:54, 719.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 finished ! Training Loss: 0.1946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "record = open('train_3d_dense_unet_elastic.txt','a')\n",
    "\n",
    "logger = {'train':[], 'validation_1':[]}\n",
    "\n",
    "for e in tqdm(range(epoch+1, epochs)):\n",
    "# iter over epoches\n",
    "\n",
    "    epoch_loss = 0\n",
    "        \n",
    "    for t, batch in enumerate(train_loader):\n",
    "    # iter over the train mini batches\n",
    "    \n",
    "        m.train()\n",
    "        # Set the model flag to train\n",
    "        # 1. enable dropout\n",
    "        # 2. batchnorm behave differently in train and test\n",
    "        #image_2 = batch['image2_data'].to(device=device, dtype=dtype)\n",
    "        #label_2 = batch['image2_label'].to(device=device, dtype=dtype)\n",
    "        \n",
    "        image_1 = batch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = batch['image1_label'].to(device=device, dtype=dtype)\n",
    "        \n",
    "        # move data to device, convert dtype to desirable dtype\n",
    "        \n",
    "        # Downsample labels to coincide with icnet model outputs\n",
    "        #label_1_resize_2 = downsample_label(label_1, 1/2)\n",
    "        #label_2_resize_2 = downsample_label(label_2, 1/2)\n",
    "        #label_4_resize_2 = downsample_label(label_4, 1/2)\n",
    "        \n",
    "        out_1 = m(image_1)\n",
    "       \n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "        # calculate loss\n",
    "        \n",
    "        epoch_loss += loss_1.item()\n",
    "        # record minibatch loss to epoch loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # set the model parameter gradient to zero\n",
    "        \n",
    "        loss_1.backward()\n",
    "        # calculate the gradient wrt loss\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        #scheduler.step(loss)\n",
    "        # take a gradient descent step\n",
    "        \n",
    "    outstr = 'Epoch {0} finished ! Training Loss: {1:.4f}'.format(e, epoch_loss/(t+1)) + '\\n'\n",
    "    \n",
    "    logger['train'].append(epoch_loss/(t+1))\n",
    "    \n",
    "    print(outstr)\n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "\n",
    "    if e%5 == 0:\n",
    "    # do validation every 5 epoches\n",
    "    \n",
    "        m.eval()\n",
    "        # set model flag to eval\n",
    "        # 1. disable dropout\n",
    "        # 2. batchnorm behave differs\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # stop taking gradient\n",
    "        \n",
    "            #valloss_4 = 0\n",
    "            #valloss_2 = 0\n",
    "            valloss_2 = 0\n",
    "            \n",
    "            for v, vbatch in enumerate(validation_loader):\n",
    "            # iter over validation mini batches\n",
    "            \n",
    "                #image_4_val = vbatch['image4_data'].to(device=device, dtype=dtype)\n",
    "                #if get_dimensions(image_4_val) == 4:\n",
    "                #    image_4_val.unsqueeze_(0)\n",
    "                #label_4_val = vbatch['image4_label'].to(device=device, dtype=dtype)\n",
    "                #if get_dimensions(label_4_val) == 4:\n",
    "                #    label_4_val.unsqueeze_(0)\n",
    "                \n",
    "                #image_2_val = vbatch['image2_data'].to(device=device, dtype=dtype)\n",
    "                #if get_dimensions(image_2_val) == 4:\n",
    "                #    image_2_val.unsqueeze_(0)\n",
    "                #label_2_val = vbatch['image2_label'].to(device=device, dtype=dtype)\n",
    "                #if get_dimensions(label_2_val) == 4:\n",
    "                #    label_2_val.unsqueeze_(0)\n",
    "                \n",
    "                image_2_val = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "                if get_dimensions(image_2_val) == 4:\n",
    "                    image_2_val.unsqueeze_(0)\n",
    "                label_2_val = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "                if get_dimensions(label_2_val) == 4:\n",
    "                    label_2_val.unsqueeze_(0)\n",
    "                \n",
    "                #print(\"image_1_val:\", image_1_val.shape)\n",
    "                #print(\"label_1_val:\", label_1_val.shape)\n",
    "                # move data to device, convert dtype to desirable dtype\n",
    "                # add dimension to labels if they are 4D tensors\n",
    "                \n",
    "                # Downsample labels to coincide with icnet model outputs\n",
    "                #label_1_val_resize_2 = downsample_label(label_1_val, 1/2) \n",
    "                #label_2_val_resize_2 = downsample_label(label_2_val, 1/2) \n",
    "                #label_4_val_resize_2 = downsample_label(label_4_val, 1/2) \n",
    "                #print(\"label_1_val_resize:\", label_1_val_resize_2.shape) \n",
    "                \n",
    "                out_2_val = m(image_2_val)\n",
    "                # do the inference\n",
    "                \n",
    "                #print(\"out_4:\", out_4_val.shape)\n",
    "                #print(\"label_4:\", label_4_val_resize_2.shape)\n",
    "                #loss_4 = dice_loss_3(out_4_val, label_4_val_resize_2)\n",
    "                #loss_2 = dice_loss_3(out_2_val, label_2_val_resize_2)\n",
    "                loss_2 = dice_loss_3(out_2_val, label_2_val)\n",
    "                # calculate loss\n",
    "\n",
    "                #valloss_4 += loss_4.item()\n",
    "                #valloss_2 += loss_2.item()\n",
    "                valloss_2 += loss_2.item()\n",
    "                # record mini batch loss\n",
    "            \n",
    "            outstr = '------- 1st valloss={0:.4f}'\\\n",
    "                .format(valloss_2/(v+1)) + '\\n'\n",
    "            \n",
    "            logger['validation_1'].append(valloss_2/(v+1))\n",
    "            \n",
    "            #scheduler.step(valloss_2/(v+1))\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            print(outstr)\n",
    "            record.write(outstr)\n",
    "            record.flush()\n",
    "            \n",
    "            #scheduler.step(valloss_2/(v+1))\n",
    "            \n",
    "            save_1('3d_dense_unet_elastic_save', m, optimizer, logger, e, scheduler)\n",
    "\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit model on single embryo image (modified ICNet Model)\n",
    "# upsample final outputs by a factor of 4 instead of factor 2\n",
    "import datetime\n",
    "from loss import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "record = open('over_fit_3d_dense_unet.txt','w+')\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    out_1 = m(image_1)\n",
    "    #out_1 = m(image_1)\n",
    "    #loss_1 = dice_loss_3(out_1, label_1)\n",
    "    loss_1 = dice_loss_3(out_1, label_1)\n",
    "    \n",
    "    #loss = loss_4 + loss_2 + loss_1 \n",
    "    loss = loss_1\n",
    "    \n",
    "    outstr = 'in epoch {}, loss = {}'.format(e, loss.item()) + '\\n'\n",
    "    \n",
    "    print(outstr) \n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
