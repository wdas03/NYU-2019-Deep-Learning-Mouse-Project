{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utility import *\n",
    "from data_utils import *\n",
    "from loss import *\n",
    "from train import *\n",
    "from deeplab_model.deeplab import *\n",
    "from dense_vnet.DenseVNet import DenseVNet\n",
    "from sync_batchnorm import convert_model\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "NUM_WORKERS = 12\n",
    "BATCH_SIZE = 2 \n",
    "\n",
    "dtype = torch.float32 \n",
    "# define dtype, float is space efficient than double\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # magic flag that accelerate\n",
    "    \n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_full_resolution_dataset(data_type = 'nii_train', \n",
    "                transform=transforms.Compose([\n",
    "                random_affine(90, 15),\n",
    "                random_filp(0.5)]))\n",
    "# do data augumentation on train dataset\n",
    "\n",
    "validation_dataset = get_full_resolution_dataset(data_type = 'nii_test', \n",
    "                transform=None)\n",
    "# no data augumentation on validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS) # drop_last\n",
    "# loaders come with auto batch division and multi-thread acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vnet import VNet\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    \n",
    "refine_model = VNet(classnum=1)\n",
    "refine_model = nn.DataParallel(refine_model)\n",
    "refine_model = convert_model(refine_model)\n",
    "refine_model = refine_model.to(device, dtype)\n",
    "\n",
    "optimizer = optim.Adam(refine_model.parameters(), lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=50)\n",
    "\n",
    "deeplab = DeepLab(output_stride=16)\n",
    "deeplab = nn.DataParallel(deeplab)\n",
    "deeplab = convert_model(deeplab)\n",
    "\n",
    "checkpoint = torch.load('../deeplab_dilated_save/2019-08-10 09:28:43.844872 epoch: 1160.pth') # best one\n",
    "\n",
    "deeplab.load_state_dict(checkpoint['state_dict_1'])\n",
    "deeplab = deeplab.to(device, dtype)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(image, label, output, batchsize):\n",
    "    image_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    label_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    output_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    for b in range(batchsize):\n",
    "        out = output[b]\n",
    "        #x, y, z = find_bv_centroid(binarize_output(out))\n",
    "        x,y,z = loadbvcenter(binarize_output(out))\n",
    "        x, y, z = np.clip([x, y, z], a_min=64, a_max=192)\n",
    "        x1 = max(x-64, 0)\n",
    "        x2 = min(x+64, 256)\n",
    "        y1 = max(y-64, 0)\n",
    "        y2 = min(y+64, 256)\n",
    "        z1 = max(z-64, 0)\n",
    "        z2 = min(z+64, 256)\n",
    "        image_final[b] = image[b, :, x1:x2, y1:y2, z1:z2]\n",
    "        label_final[b] = label[b, :, x1:x2, y1:y2, z1:z2]\n",
    "        output_final[b] = output[b, :, x1:x2, y1:y2, z1:z2]\n",
    "    return image_final, label_final, output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9670, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9658, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9776, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9363, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9670, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9883, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9528, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9753, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9646, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9875, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9754, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9682, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9625, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9725, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9623, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9389, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9807, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9608, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9659, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9354, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9832, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9797, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9586, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9422, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9699, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9654, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9381, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8979, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9736, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9305, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9882, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9855, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9280, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9046, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9398, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9848, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9240, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9031, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9709, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9259, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9575, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9239, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9035, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8979, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9895, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9128, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9090, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9223, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9482, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9663, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9925, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9305, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8588, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9646, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9358, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8762, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9011, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9285, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9314, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8323, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8072, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8967, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8178, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8420, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8613, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8915, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8296, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9583, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/4999 [16:35<1382:01:19, 995.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished ! Training Loss: 0.9360\n",
      "\n",
      "tensor(0.8582, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7597, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7478, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7567, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8759, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8312, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8983, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7386, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7208, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7124, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7377, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7748, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6369, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7189, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9583, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7108, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4721, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7021, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7259, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4793, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7469, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9253, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5362, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4520, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6197, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5720, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3921, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3229, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6194, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7776, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5594, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5921, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3030, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6359, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3213, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5361, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3693, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2466, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4314, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4914, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6301, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9881, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9731, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2060, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9585, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2399, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4690, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1206, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6419, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4189, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1498, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3588, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6075, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3001, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5712, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4665, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2317, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4222, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5748, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3403, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9845, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5478, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2721, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5410, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2542, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 2 finished ! Training Loss: 0.5811\n",
      "\n",
      "tensor(0.2889, device='cuda:0')\n",
      "tensor(0.1488, device='cuda:0')\n",
      "tensor(0.2349, device='cuda:0')\n",
      "tensor(0.1895, device='cuda:0')\n",
      "tensor(0.3274, device='cuda:0')\n",
      "tensor(0.2559, device='cuda:0')\n",
      "tensor(0.1729, device='cuda:0')\n",
      "tensor(0.3726, device='cuda:0')\n",
      "tensor(0.1520, device='cuda:0')\n",
      "tensor(0.1602, device='cuda:0')\n",
      "tensor(0.2166, device='cuda:0')\n",
      "tensor(0.1693, device='cuda:0')\n",
      "tensor(0.6634, device='cuda:0')\n",
      "tensor(0.3899, device='cuda:0')\n",
      "tensor(0.3285, device='cuda:0')\n",
      "tensor(0.1671, device='cuda:0')\n",
      "tensor(0.1878, device='cuda:0')\n",
      "tensor(0.1851, device='cuda:0')\n",
      "tensor(0.3116, device='cuda:0')\n",
      "tensor(0.1592, device='cuda:0')\n",
      "tensor(0.1974, device='cuda:0')\n",
      "tensor(0.3398, device='cuda:0')\n",
      "tensor(0.2572, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/4999 [32:55<1375:21:02, 990.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 2 saved !\n",
      "------- 1st valloss=0.2555\n",
      "\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1398, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2177, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1354, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2925, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7219, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2554, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6262, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5221, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2111, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1741, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2063, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5845, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5716, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5341, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2615, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3125, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1652, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1696, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9858, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1398, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6355, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1240, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2216, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1250, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6082, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9913, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5405, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2819, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1667, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0925, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1923, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5404, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9923, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2693, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1400, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3414, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0951, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2167, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9915, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1847, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1408, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1393, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3489, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4114, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1206, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5793, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7520, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5765, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2095, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5602, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3043, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9852, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6464, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3563, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5792, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1622, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1351, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5558, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5391, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5525, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4214, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6241, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6083, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5527, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/4999 [47:56<1337:28:25, 963.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished ! Training Loss: 0.3888\n",
      "\n",
      "tensor(0.1592, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1371, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1518, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5792, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1338, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1552, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4734, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5469, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5864, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4868, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5389, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5614, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1199, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9981, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6769, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9786, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6459, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1067, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6301, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5632, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1531, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2396, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1848, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1555, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1921, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5626, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1852, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6050, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5485, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1156, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2501, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5479, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5892, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1833, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9282, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6011, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1420, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1547, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1741, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2265, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5625, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1539, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1966, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1190, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1948, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5483, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5312, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4670, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6257, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2078, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1152, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1162, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9884, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1459, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5720, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5808, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0975, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2851, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1650, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1550, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5667, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1718, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3126, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1459, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5723, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 4 finished ! Training Loss: 0.3739\n",
      "\n",
      "tensor(0.1439, device='cuda:0')\n",
      "tensor(0.1365, device='cuda:0')\n",
      "tensor(0.2565, device='cuda:0')\n",
      "tensor(0.2633, device='cuda:0')\n",
      "tensor(0.3184, device='cuda:0')\n",
      "tensor(0.1800, device='cuda:0')\n",
      "tensor(0.3071, device='cuda:0')\n",
      "tensor(0.1861, device='cuda:0')\n",
      "tensor(0.1950, device='cuda:0')\n",
      "tensor(0.1970, device='cuda:0')\n",
      "tensor(0.2508, device='cuda:0')\n",
      "tensor(0.3144, device='cuda:0')\n",
      "tensor(0.2447, device='cuda:0')\n",
      "tensor(0.1264, device='cuda:0')\n",
      "tensor(0.1604, device='cuda:0')\n",
      "tensor(0.1234, device='cuda:0')\n",
      "tensor(0.1196, device='cuda:0')\n",
      "tensor(0.1321, device='cuda:0')\n",
      "tensor(0.1175, device='cuda:0')\n",
      "tensor(0.4944, device='cuda:0')\n",
      "tensor(0.1646, device='cuda:0')\n",
      "tensor(0.1490, device='cuda:0')\n",
      "tensor(0.1675, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/4999 [1:04:03<1338:35:17, 964.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 4 saved !\n",
      "------- 1st valloss=0.2065\n",
      "\n",
      "tensor(0.2631, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3024, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1757, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1576, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6171, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9926, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0778, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2183, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1500, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5739, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1804, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5412, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5639, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5506, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5806, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2360, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1498, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0966, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1908, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5930, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4229, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1249, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4273, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0913, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5391, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2690, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9870, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5658, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5646, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5315, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1939, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5596, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2646, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5341, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6777, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1302, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1893, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5928, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1854, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9429, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2534, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1942, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5950, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7092, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5877, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1370, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2713, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5815, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5848, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1480, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1313, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2183, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5587, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5624, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1254, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1782, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6109, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6122, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/4999 [1:19:14<1315:55:51, 948.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished ! Training Loss: 0.3679\n",
      "\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1257, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1351, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5918, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9955, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5592, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3231, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2125, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2325, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5309, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1834, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1125, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9929, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1641, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6214, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1398, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5489, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2393, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5599, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5449, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5908, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5395, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5611, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1459, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1283, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5778, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1053, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2842, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2021, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5272, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5743, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6780, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5932, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5680, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5559, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0954, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0933, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5477, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1356, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5580, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1658, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5225, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1946, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5567, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2594, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1334, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1919, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5552, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5646, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.0771, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5527, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1515, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9927, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2580, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7171, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2065, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1537, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2098, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1384, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1465, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5530, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6211, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2128, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1664, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5559, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 6 finished ! Training Loss: 0.3666\n",
      "\n",
      "tensor(0.1352, device='cuda:0')\n",
      "tensor(0.1712, device='cuda:0')\n",
      "tensor(0.2094, device='cuda:0')\n",
      "tensor(0.3721, device='cuda:0')\n",
      "tensor(0.1102, device='cuda:0')\n",
      "tensor(0.2004, device='cuda:0')\n",
      "tensor(0.1437, device='cuda:0')\n",
      "tensor(0.1461, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.1389, device='cuda:0')\n",
      "tensor(0.1857, device='cuda:0')\n",
      "tensor(0.1101, device='cuda:0')\n",
      "tensor(0.1645, device='cuda:0')\n",
      "tensor(0.2450, device='cuda:0')\n",
      "tensor(0.1249, device='cuda:0')\n",
      "tensor(0.1846, device='cuda:0')\n",
      "tensor(0.1406, device='cuda:0')\n",
      "tensor(0.1381, device='cuda:0')\n",
      "tensor(0.1076, device='cuda:0')\n",
      "tensor(0.1976, device='cuda:0')\n",
      "tensor(0.1425, device='cuda:0')\n",
      "tensor(0.1756, device='cuda:0')\n",
      "tensor(0.1456, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/4999 [1:35:23<1324:23:49, 954.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 6 saved !\n",
      "------- 1st valloss=0.1686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "record = open('train_bv_refine_6.txt','a+')\n",
    "\n",
    "logger = {'train':[], 'validation_1': []}\n",
    "\n",
    "min_val = 1\n",
    "\n",
    "for e in tqdm(range(epoch + 1, epochs)):\n",
    "# iter over epoches\n",
    "    epoch_loss = 0\n",
    "        \n",
    "    for t, batch in enumerate(train_loader):\n",
    "    # iter over the train mini batches\n",
    "        refine_model.train()\n",
    "        deeplab.eval()\n",
    "        # Set the model flag to train\n",
    "        # 1. enable dropout\n",
    "        # 2. batchnorm behave differently in train and test\n",
    "        #print(batch['image1_data'])\n",
    "        image_1 = batch['image1_data'].to(device=device, dtype=dtype)\n",
    "        image_1 = image_1.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        label_1 = batch['image1_label'].to(device=device, dtype=dtype)\n",
    "        label_1 = label_1.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "        bv_label = label_1[:, 2, :, :, :]\n",
    "        bv_label = bv_label.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        #original_res = [a[minibatch].item() for a in batch['original_resolution']]\n",
    "\n",
    "        # Get coarse output from deeplab model from 256 resolution input\n",
    "        out_coarse = deeplab(image_1)\n",
    "        out_coarse = out_coarse.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "        bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "        bv_coarse = bv_coarse.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "        #bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "        \n",
    "        bbox_concat = torch.cat([bbox_image, bbox_bv], dim=1)\n",
    "        \n",
    "        #show_image_slice(label_1)\n",
    "        #show_image_slice(bv_label)\n",
    "        #show_image_slice(bbox_image)\n",
    "        #show_image_slice(bbox_label)\n",
    "        #show_image_slice(bbox_bv)\n",
    "\n",
    "        #print(\"bbox_concat\", bbox_concat.shape)\n",
    "\n",
    "        del out_coarse\n",
    "        del image_1\n",
    "        del bv_coarse\n",
    "        del label_1\n",
    "        del bv_label\n",
    "        del bbox_image\n",
    "        del bbox_bv\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        refine_out = refine_model(bbox_concat)\n",
    "        # do the inference\n",
    "\n",
    "        #print(refine_out.shape)\n",
    "        #print(bbox_bv_label.shape)\n",
    "\n",
    "        loss = dice_loss(refine_out, bbox_label)\n",
    "        \n",
    "        print(loss)\n",
    "        epoch_loss += loss.item()\n",
    "        # record minibatch loss to epoch loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # set the model parameter gradient to zero\n",
    "        \n",
    "        loss.backward()\n",
    "        # calculate the gradient wrt loss\n",
    "        optimizer.step()\n",
    "        # take a gradient descent step\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    outstr = 'Epoch {0} finished ! Training Loss: {1:.4f}'.format(e, epoch_loss/(t+1)) + '\\n'\n",
    "    \n",
    "    logger['train'].append(epoch_loss/(t+1))\n",
    "    \n",
    "    print(outstr)\n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "\n",
    "    if e%2 == 0:\n",
    "    # do validation every 5 epoches\n",
    "        deeplab.eval()\n",
    "        refine_model.eval()\n",
    "        # set model flag to eval\n",
    "        # 1. disable dropout\n",
    "        # 2. batchnorm behave differs\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # stop taking gradient\n",
    "        \n",
    "            #valloss_4 = 0\n",
    "            #valloss_2 = 0\n",
    "            valloss_1 = 0\n",
    "            \n",
    "            for v, vbatch in enumerate(validation_loader):\n",
    "                image_1 = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "                image_1 = image_1.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                label_1 = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "                label_1 = label_1.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "                bv_label = label_1[:, 2, :, :, :]\n",
    "                bv_label = bv_label.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                #original_res = [a[minibatch].item() for a in batch['original_resolution']]\n",
    "\n",
    "                # Get coarse output from deeplab model from 256 resolution input\n",
    "                out_coarse = deeplab(image_1)\n",
    "                out_coarse = out_coarse.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "                bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "                bv_coarse = bv_coarse.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "\n",
    "                bbox_concat = torch.cat([bbox_image, bbox_bv], dim=1)\n",
    "\n",
    "                #show_image_slice(label)\n",
    "                #show_image_slice(bbox_image)\n",
    "                #show_image_slice(bbox_label)\n",
    "                #show_image_slice(bbox_bv)\n",
    "\n",
    "                #print(\"bbox_concat\", bbox_concat.shape)\n",
    "                #seg_image_concat = torch.cat([bv_coarse, image_1], dim=1)\n",
    "\n",
    "                del out_coarse\n",
    "                del image_1\n",
    "                del bv_coarse\n",
    "                del label_1\n",
    "                del bv_label\n",
    "                del bbox_image\n",
    "                del bbox_bv\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                refine_out = refine_model(bbox_concat)\n",
    "                        \n",
    "                loss = dice_loss(refine_out, bbox_label)\n",
    "                \n",
    "                print(loss)\n",
    "            \n",
    "                # calculate loss\n",
    "                valloss_1 += loss.item()\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            \n",
    "            avg_val_loss = (valloss_1 / (v+1))\n",
    "            outstr = '------- 1st valloss={0:.4f}'\\\n",
    "                .format(avg_val_loss) + '\\n'\n",
    "            \n",
    "            logger['validation_1'].append(avg_val_loss)\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            if avg_val_loss < min_val:\n",
    "                save_1('refine_bv6_save', refine_model, optimizer, logger, e, scheduler)\n",
    "            elif e % 10 == 0:\n",
    "                save_1('refine_bv6_save', refine_model, optimizer, logger, e, scheduler)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            print(outstr)\n",
    "            record.write(outstr)\n",
    "            record.flush()\n",
    "    \n",
    "\n",
    "\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    bgloss = 0\n",
    "    bdloss = 0\n",
    "    bvloss = 0\n",
    "    \n",
    "    for v, vbatch in tqdm(enumerate(validation_loader)):\n",
    "        # move data to device, convert dtype to desirable dtype\n",
    "        image_1 = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "\n",
    "        output = deeplab(image_1)\n",
    "        # do the inference\n",
    "        output_numpy = output.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        #out_1 = torch.round(output)\n",
    "        out_1 = torch.from_numpy((output_numpy == output_numpy.max(axis=1)[:, None]).astype(int)).to(device=device, dtype=dtype)\n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "\n",
    "        bg, bd, bv = dice_loss_3_debug(out_1, label_1)\n",
    "        # calculate loss\n",
    "        print(bg.item(), bd.item(), bv.item(), loss_1.item())\n",
    "        bgloss += bg.item()\n",
    "        bdloss += bd.item()\n",
    "        bvloss += bv.item()\n",
    "        \n",
    "        if bv.item() >= 0.2 or bd.item() >= 0.1:\n",
    "            show_image_slice(image_1)\n",
    "            show_image_slice(label_1)\n",
    "            show_image_slice(output)\n",
    "\n",
    "    outstr = '------- background loss = {0:.4f}, body loss = {1:.4f}, bv loss = {2:.4f}'\\\n",
    "        .format(bgloss/(v+1), bdloss/(v+1), bvloss/(v+1)) + '\\n'\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
