{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utility import *\n",
    "from dense_vnet.DenseVNet import *\n",
    "from data_utils import get_dimensions\n",
    "from loss import *\n",
    "import adabound\n",
    "from train import *\n",
    "from sync_batchnorm import convert_model\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "NUM_WORKERS = 12\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "dtype = torch.float32 \n",
    "# define dtype, float is space efficient than double\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # magic flag that accelerate\n",
    "    \n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pyramid_dataset(data_type = 'nii_train', \n",
    "                transform=transforms.Compose([\n",
    "                random_affine(90, 15),\n",
    "                random_filp(0.5)]))\n",
    "# do data augumentation on train dataset\n",
    "\n",
    "validation_dataset = pyramid_dataset(data_type = 'nii_test', \n",
    "                transform=None)\n",
    "# no data augumentation on validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "# loaders come with auto batch division and multi-thread acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dictionary = train_dataset[33]\n",
    "\n",
    "#image_2 = test_dictionary['image2_data'].view(1, 1, 128, 128, 128)\n",
    "#label_2 = test_dictionary['image2_label'].view(1, 3, 128, 128, 128)\n",
    "\n",
    "image_1 = test_dictionary['image1_data'].view(1, 1, 256, 256, 256)\n",
    "label_1 = test_dictionary['image1_label'].view(1, 3, 256, 256, 256)\n",
    "\n",
    "#image_2 = image_2.to(device=device, dtype=dtype)  \n",
    "#label_2 = label_2.to(device=device, dtype=dtype)\n",
    "\n",
    "image_1 = image_1.to(device=device, dtype=dtype) \n",
    "label_1 = label_1.to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv3d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "    elif isinstance(m, nn.BatchNorm3d):\n",
    "        init.normal_(m.weight.data, mean=0, std=1)\n",
    "\n",
    "def downsample_label(label, scale_factor):\n",
    "    return F.interpolate(label, scale_factor=scale_factor, mode='trilinear', align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_test(model, cuda_bool):\n",
    "    x = torch.zeros((1, 1, 256, 256, 256))\n",
    "    x = x.to(device=device, dtype=dtype) if cuda_bool else x\n",
    "    model = model.to(device=device, dtype=dtype) if cuda_bool else x\n",
    "    scores = model(x)\n",
    "    for i in scores:\n",
    "        print(i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndense_vnet = DenseVNet()\\ndense_vnet = nn.DataParallel(dense_vnet)\\ndense_vnet = convert_model(dense_vnet)\\ndense_vnet.apply(init_weights)\\ndense_vnet = dense_vnet.to(device=device, dtype=dtype)\\n\\n#shape_test(dense_vnet, True)\\n\\n#optimizer = optim.Adam(dense_vnet.parameters(), lr=1e-3)\\noptimizer = adabound.AdaBound(dense_vnet.parameters(), lr=1e-3, final_lr=0.1)\\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\\nepoch = 0\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dense_vnet = DenseVNet()\n",
    "dense_vnet = nn.DataParallel(dense_vnet)\n",
    "dense_vnet = convert_model(dense_vnet)\n",
    "dense_vnet.apply(init_weights)\n",
    "dense_vnet = dense_vnet.to(device=device, dtype=dtype)\n",
    "\n",
    "#shape_test(dense_vnet, True)\n",
    "\n",
    "#optimizer = optim.Adam(dense_vnet.parameters(), lr=1e-3)\n",
    "optimizer = adabound.AdaBound(dense_vnet.parameters(), lr=1e-3, final_lr=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "epoch = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dense_vnet = DenseVNet(num_classes=3)\n",
    "dense_vnet = nn.DataParallel(dense_vnet)\n",
    "dense_vnet = convert_model(dense_vnet)\n",
    "\n",
    "#checkpoint = torch.load('../dense_vnet_dropout_save/2019-08-10 18:50:56.964852 epoch: 675.pth') # best one\n",
    "#checkpoint = torch.load('../dense_vnet_dropout_save/2019-08-11 04:09:10.113433 epoch: 759.pth')\n",
    "checkpoint = torch.load('../dense_vnet_dropout_save/2019-08-12 11:58:04.178603 epoch: 1039.pth')\n",
    "\n",
    "dense_vnet.load_state_dict(checkpoint['state_dict_1'])\n",
    "dense_vnet = dense_vnet.to(device=device, dtype=dtype)\n",
    "\n",
    "optimizer = optim.Adam(dense_vnet.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "#optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(epoch)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3960 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040 finished ! Training Loss: 0.0788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/3960 [07:54<522:20:57, 474.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0613\n",
      "\n",
      "Checkpoint 1040 saved !\n",
      "Epoch 1041 finished ! Training Loss: 0.0823\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/3960 [14:47<501:34:46, 456.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0603\n",
      "\n",
      "Epoch 1042 finished ! Training Loss: 0.0811\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/3960 [21:51<490:46:54, 446.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0629\n",
      "\n",
      "Epoch 1043 finished ! Training Loss: 0.0786\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/3960 [28:44<479:44:10, 436.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0612\n",
      "\n",
      "Epoch 1044 finished ! Training Loss: 0.0795\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/3960 [35:51<476:33:17, 433.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0607\n",
      "\n",
      "Epoch 1045 finished ! Training Loss: 0.0780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/3960 [42:54<472:47:06, 430.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0624\n",
      "\n",
      "Epoch 1046 finished ! Training Loss: 0.0790\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/3960 [49:48<467:18:44, 425.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0604\n",
      "\n",
      "Epoch 1047 finished ! Training Loss: 0.0766\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/3960 [56:52<466:29:47, 424.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0643\n",
      "\n",
      "Epoch 1048 finished ! Training Loss: 0.0762\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/3960 [1:04:01<467:43:35, 426.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0595\n",
      "\n",
      "Epoch 1049 finished ! Training Loss: 0.0776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/3960 [1:10:54<463:20:51, 422.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0622\n",
      "\n",
      "Epoch 1050 finished ! Training Loss: 0.0823\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 11/3960 [1:17:59<464:14:54, 423.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0702\n",
      "\n",
      "Checkpoint 1050 saved !\n",
      "Epoch 1051 finished ! Training Loss: 0.0780\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 12/3960 [1:24:55<461:45:29, 421.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0655\n",
      "\n",
      "Epoch 1052 finished ! Training Loss: 0.0782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 13/3960 [1:31:54<460:56:52, 420.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0622\n",
      "\n",
      "Epoch 1053 finished ! Training Loss: 0.0763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 14/3960 [1:38:50<459:12:55, 418.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0627\n",
      "\n",
      "Epoch 1054 finished ! Training Loss: 0.0787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 15/3960 [1:45:44<457:37:02, 417.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0627\n",
      "\n",
      "Epoch 1055 finished ! Training Loss: 0.0750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 16/3960 [1:52:39<456:23:34, 416.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0643\n",
      "\n",
      "Epoch 1056 finished ! Training Loss: 0.0775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 17/3960 [1:59:28<453:48:24, 414.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0708\n",
      "\n",
      "Epoch 1057 finished ! Training Loss: 0.0769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 18/3960 [2:06:33<457:18:49, 417.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0656\n",
      "\n",
      "Epoch 1058 finished ! Training Loss: 0.0784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 19/3960 [2:13:37<459:21:48, 419.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0692\n",
      "\n",
      "Epoch 1059 finished ! Training Loss: 0.0798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 20/3960 [2:20:38<459:33:05, 419.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0665\n",
      "\n",
      "Epoch 1060 finished ! Training Loss: 0.0772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 21/3960 [2:27:31<457:09:52, 417.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0658\n",
      "\n",
      "Checkpoint 1060 saved !\n",
      "Epoch 1061 finished ! Training Loss: 0.0746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 22/3960 [2:34:35<458:59:58, 419.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0639\n",
      "\n",
      "Epoch 1062 finished ! Training Loss: 0.0753\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 23/3960 [2:41:28<456:59:12, 417.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0637\n",
      "\n",
      "Epoch 1063 finished ! Training Loss: 0.0757\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 24/3960 [2:48:26<456:47:38, 417.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0610\n",
      "\n",
      "Epoch 1064 finished ! Training Loss: 0.0755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 25/3960 [2:55:22<456:10:30, 417.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0606\n",
      "\n",
      "Epoch 1065 finished ! Training Loss: 0.0738\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 26/3960 [3:02:17<455:12:18, 416.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0594\n",
      "\n",
      "Epoch 1066 finished ! Training Loss: 0.0781\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 27/3960 [3:09:09<453:43:31, 415.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0601\n",
      "\n",
      "Epoch 1067 finished ! Training Loss: 0.0737\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 28/3960 [3:16:01<452:18:24, 414.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0716\n",
      "\n",
      "Epoch 1068 finished ! Training Loss: 0.0756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 29/3960 [3:23:01<454:15:43, 416.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0614\n",
      "\n",
      "Epoch 1069 finished ! Training Loss: 0.0746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 30/3960 [3:30:05<456:48:15, 418.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0619\n",
      "\n",
      "Epoch 1070 finished ! Training Loss: 0.0770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 31/3960 [3:37:13<459:50:49, 421.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0628\n",
      "\n",
      "Checkpoint 1070 saved !\n",
      "Epoch 1071 finished ! Training Loss: 0.0762\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 32/3960 [3:44:13<459:06:51, 420.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0630\n",
      "\n",
      "Epoch 1072 finished ! Training Loss: 0.0788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 33/3960 [3:51:07<456:59:59, 418.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0653\n",
      "\n",
      "Epoch 1073 finished ! Training Loss: 0.0742\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 34/3960 [3:58:00<454:42:43, 416.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1st valloss=0.0631\n",
      "\n",
      "Epoch 1074 finished ! Training Loss: 0.0761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "record = open('dense_vnet/train_dense_vnet_dropout.txt','a+')\n",
    "\n",
    "logger = {'train':[], 'validation_1':[]}\n",
    "\n",
    "min_val = .0581\n",
    "\n",
    "for e in tqdm(range(epoch + 1, epochs)):\n",
    "# iter over epoches\n",
    "\n",
    "    epoch_loss = 0\n",
    "        \n",
    "    for t, batch in enumerate(train_loader):\n",
    "        \n",
    "        # iter over the train mini batches\n",
    "    \n",
    "        dense_vnet.train()\n",
    "        # Set the model flag to train\n",
    "        # 1. enable dropout\n",
    "        # 2. batchnorm behave differently in train and test\n",
    "        \n",
    "        image_1 = batch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = batch['image1_label'].to(device=device, dtype=dtype)\n",
    "        # move data to device, convert dtype to desirable dtype\n",
    "        \n",
    "        out_1 = dense_vnet(image_1)\n",
    "       \n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "        # calculate loss\n",
    "        \n",
    "        epoch_loss += loss_1.item()\n",
    "        # record minibatch loss to epoch loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # set the model parameter gradient to zero\n",
    "        \n",
    "        loss_1.backward()\n",
    "        # calculate the gradient wrt loss\n",
    "        \n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss)\n",
    "        # take a gradient descent step\n",
    "        \n",
    "    outstr = 'Epoch {0} finished ! Training Loss: {1:.4f}'.format(e, epoch_loss/(t+1)) + '\\n'\n",
    "    \n",
    "    logger['train'].append(epoch_loss/(t+1))\n",
    "    \n",
    "    print(outstr)\n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "\n",
    "    if e%1 == 0:\n",
    "    # do validation every n epochs\n",
    "    \n",
    "        dense_vnet.eval()\n",
    "        # set model flag to eval\n",
    "        # 1. disable dropout\n",
    "        # 2. batchnorm behave differs\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # stop taking gradient\n",
    "            valloss_1 = 0\n",
    "            \n",
    "            for v, vbatch in enumerate(validation_loader):\n",
    "            # iter over validation mini batches\n",
    "                image_1_val = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "                if get_dimensions(image_1_val) == 4:\n",
    "                    image_1_val.unsqueeze_(0)\n",
    "                label_1_val = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "                if get_dimensions(label_1_val) == 4:\n",
    "                    label_1_val.unsqueeze_(0)\n",
    "                \n",
    "                out_1_val = dense_vnet(image_1_val)\n",
    "                # do the inference\n",
    "                \n",
    "                loss_1 = dice_loss_3(out_1_val, label_1_val)\n",
    "                # calculate loss\n",
    "\n",
    "                valloss_1 += loss_1.item()\n",
    "                # record mini batch loss\n",
    "            \n",
    "            outstr = '------- 1st valloss={0:.4f}'\\\n",
    "                .format(valloss_1/(v+1)) + '\\n'\n",
    "            \n",
    "            logger['validation_1'].append(valloss_1/(v+1))\n",
    "            avg_val_loss = valloss_1 / (v+1)\n",
    "            #scheduler.step(valloss_1/(v+1))\n",
    "            \n",
    "            print(outstr)\n",
    "            record.write(outstr)\n",
    "            record.flush()\n",
    "            \n",
    "            if avg_val_loss < min_val:\n",
    "                min_val = avg_val_loss\n",
    "                save_1('dense_vnet_dropout_save', dense_vnet, optimizer, logger, e, scheduler)\n",
    "            elif e % 10 == 0:\n",
    "                save_1('dense_vnet_dropout_save', dense_vnet, optimizer, logger, e, scheduler)\n",
    "            #torch.cuda.empty_cache()\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_vnet.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    bgloss = 0\n",
    "    bdloss = 0\n",
    "    bvloss = 0\n",
    "    \n",
    "    for v, vbatch in tqdm(enumerate(validation_loader)):\n",
    "            # move data to device, convert dtype to desirable dtype\n",
    "\n",
    "        image_1 = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "\n",
    "        output = dense_vnet(image_1)\n",
    "        # do the inference\n",
    "        output_numpy = output.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        #out_1 = torch.round(output)\n",
    "        out_1 = torch.from_numpy((output_numpy == output_numpy.max(axis=1)[:, None]).astype(int)).to(device=device, dtype=dtype)\n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "\n",
    "        bg, bd, bv = dice_loss_3_debug(out_1, label_1)\n",
    "        # calculate loss\n",
    "        print(bg.item(), bd.item(), bv.item(), loss_1.item())\n",
    "        bgloss += bg.item()\n",
    "        bdloss += bd.item()\n",
    "        bvloss += bv.item()\n",
    "\n",
    "    outstr = '------- background loss = {0:.4f}, body loss = {1:.4f}, bv loss = {2:.4f}'\\\n",
    "        .format(bgloss/(v+1), bdloss/(v+1), bvloss/(v+1)) + '\\n'\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit model on single embryo image (modified ICNet Model)\n",
    "# upsample final outputs by a factor of 4 instead of factor 2\n",
    "import datetime\n",
    "from loss import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "record = open('over_fit_dense_vnet3.txt','w+')\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    \n",
    "    \n",
    "    out_2 = dense_vnet(image_1)\n",
    "    \n",
    "    #loss_1 = dice_loss_3(out_1, label_1)\n",
    "    loss_2 = dice_loss_3(out_2, label_1)\n",
    "    \n",
    "    #loss = loss_1 + loss_2\n",
    "    \n",
    "    outstr = 'in epoch {}, loss_2 = {}'.format(e, loss_2.item()) + '\\n'\n",
    "    \n",
    "    print(outstr) \n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_2.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "record.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
