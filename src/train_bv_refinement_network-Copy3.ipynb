{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utility import *\n",
    "from data_utils import *\n",
    "from loss import *\n",
    "from train import *\n",
    "from deeplab_model.deeplab import *\n",
    "from dense_vnet.DenseVNet import DenseVNet\n",
    "from sync_batchnorm import convert_model\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "NUM_WORKERS = 12\n",
    "BATCH_SIZE = 2 \n",
    "\n",
    "dtype = torch.float32 \n",
    "# define dtype, float is space efficient than double\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # magic flag that accelerate\n",
    "    \n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_full_resolution_dataset(data_type = 'nii_train', \n",
    "                transform=transforms.Compose([\n",
    "                random_affine(90, 15),\n",
    "                random_filp(0.5)]))\n",
    "# do data augumentation on train dataset\n",
    "\n",
    "validation_dataset = get_full_resolution_dataset(data_type = 'nii_test', \n",
    "                transform=None)\n",
    "# no data augumentation on validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS) # drop_last\n",
    "# loaders come with auto batch division and multi-thread acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "from bv_refinement_network.RefinementModel import RefinementModel, RefinementModel_NoDown\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    \n",
    "refine_model = RefinementModel(num_classes=1)\n",
    "refine_model = nn.DataParallel(refine_model)\n",
    "refine_model = convert_model(refine_model)\n",
    "refine_model = refine_model.to(device, dtype)\n",
    "\n",
    "optimizer = optim.Adam(refine_model.parameters(), lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=25)\n",
    "\n",
    "deeplab = DeepLab(output_stride=16)\n",
    "deeplab = nn.DataParallel(deeplab)\n",
    "deeplab = convert_model(deeplab)\n",
    "\n",
    "checkpoint = torch.load('../deeplab_dilated_save/2019-08-10 09:28:43.844872 epoch: 1160.pth') # best one\n",
    "\n",
    "deeplab.load_state_dict(checkpoint['state_dict_1'])\n",
    "deeplab = deeplab.to(device, dtype)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest_dictionary = train_dataset[33]\\n\\nimage_1 = test_dictionary['image1_data'].view(1, 1, 256, 256, 256)\\nlabel_1 = test_dictionary['image1_label'].view(1, 3, 256, 256, 256)\\nbv_label = label_1.narrow(1,2,1).to(device, dtype)\\nif get_dimensions(bv_label) == 4:\\n    bv_label.unsqueeze_(0)\\n\\nimage_1 = image_1.to(device=device, dtype=dtype) \\nlabel_1 = label_1.to(device=device, dtype=dtype)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "test_dictionary = train_dataset[33]\n",
    "\n",
    "image_1 = test_dictionary['image1_data'].view(1, 1, 256, 256, 256)\n",
    "label_1 = test_dictionary['image1_label'].view(1, 3, 256, 256, 256)\n",
    "bv_label = label_1.narrow(1,2,1).to(device, dtype)\n",
    "if get_dimensions(bv_label) == 4:\n",
    "    bv_label.unsqueeze_(0)\n",
    "\n",
    "image_1 = image_1.to(device=device, dtype=dtype) \n",
    "label_1 = label_1.to(device=device, dtype=dtype)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(image, label, output, batchsize):\n",
    "    image_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    label_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    output_final = torch.zeros((batchsize, 1, 128, 128, 128)).to(device, dtype)\n",
    "    for b in range(batchsize):\n",
    "        out = output[b]\n",
    "        x, y, z = find_bv_centroid(binarize_output(out))\n",
    "        #x,y,z = loadbvcenter(binarize_output(out))\n",
    "        x, y, z = np.clip([x, y, z], a_min=64, a_max=192)\n",
    "        x1 = max(x-64, 0)\n",
    "        x2 = min(x+64, 256)\n",
    "        y1 = max(y-64, 0)\n",
    "        y2 = min(y+64, 256)\n",
    "        z1 = max(z-64, 0)\n",
    "        z2 = min(z+64, 256)\n",
    "        image_final[b] = image[b, :, x1:x2, y1:y2, z1:z2]\n",
    "        label_final[b] = label[b, :, x1:x2, y1:y2, z1:z2]\n",
    "        output_final[b] = output[b, :, x1:x2, y1:y2, z1:z2]\n",
    "    return image_final, label_final, output_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9966, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9981, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9234, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9878, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8701, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5934, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6249, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7340, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9872, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9479, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9802, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7627, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9506, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9796, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7183, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6271, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2679, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9586, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9989, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9733, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7927, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6649, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7065, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7097, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6353, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5916, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6280, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2623, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6246, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5250, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6942, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2904, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3300, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9928, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8840, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7614, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5981, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6285, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5203, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6842, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3942, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9989, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9982, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5838, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4514, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3541, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6886, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6283, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6681, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2684, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4468, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3793, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9993, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6071, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4282, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6370, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/4999 [12:49<1068:37:03, 769.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished ! Training Loss: 0.7244\n",
      "\n",
      "tensor(0.5967, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5123, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1781, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5242, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6567, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6049, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3090, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3792, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3967, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5835, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6485, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9911, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6993, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7677, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2983, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7216, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4203, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6286, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5314, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6791, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6733, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8941, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7679, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5869, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3451, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6758, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3013, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2344, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6961, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3707, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6775, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6434, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3599, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6655, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2761, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6138, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9119, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2755, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5792, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5701, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9979, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6118, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3405, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3126, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3412, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6445, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9702, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2774, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2512, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5696, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6085, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4359, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6944, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6752, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3572, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7543, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2933, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3060, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2531, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6979, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6099, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 2 finished ! Training Loss: 0.5830\n",
      "\n",
      "tensor(0.3091, device='cuda:0')\n",
      "tensor(0.4154, device='cuda:0')\n",
      "tensor(0.3072, device='cuda:0')\n",
      "tensor(0.1705, device='cuda:0')\n",
      "tensor(0.5601, device='cuda:0')\n",
      "tensor(0.2816, device='cuda:0')\n",
      "tensor(0.3109, device='cuda:0')\n",
      "tensor(0.3515, device='cuda:0')\n",
      "tensor(0.3461, device='cuda:0')\n",
      "tensor(0.2168, device='cuda:0')\n",
      "tensor(0.3407, device='cuda:0')\n",
      "tensor(0.3399, device='cuda:0')\n",
      "tensor(0.2508, device='cuda:0')\n",
      "tensor(0.3953, device='cuda:0')\n",
      "tensor(0.3050, device='cuda:0')\n",
      "tensor(0.3611, device='cuda:0')\n",
      "tensor(0.4130, device='cuda:0')\n",
      "tensor(0.2210, device='cuda:0')\n",
      "tensor(0.3388, device='cuda:0')\n",
      "tensor(0.2868, device='cuda:0')\n",
      "tensor(0.3027, device='cuda:0')\n",
      "tensor(0.3177, device='cuda:0')\n",
      "tensor(0.3048, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/4999 [25:29<1064:07:52, 766.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 2 saved !\n",
      "------- 1st valloss=0.3238\n",
      "\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6184, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6456, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6071, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6986, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6276, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6201, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5902, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8522, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8416, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6334, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7896, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2704, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5953, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4291, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3088, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8931, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9666, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3635, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7176, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6780, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8473, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8006, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3391, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3732, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9939, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6652, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3057, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6216, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3327, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3969, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4016, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3052, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5201, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3157, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7713, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6826, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6650, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4478, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1776, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4062, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2912, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5931, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3671, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1581, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2319, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6043, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7333, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6663, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2308, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3551, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6415, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2972, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2511, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7858, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6195, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3526, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7614, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3292, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/4999 [37:10<1036:44:36, 747.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished ! Training Loss: 0.5693\n",
      "\n",
      "tensor(0.4445, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5967, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9970, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3489, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6303, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7854, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6721, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3771, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4120, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3254, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9972, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6054, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6970, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4234, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6682, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2807, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8560, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2927, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3579, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3256, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6195, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7102, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6927, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9994, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3361, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6266, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6404, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5838, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3053, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4183, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7289, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7279, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6630, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6156, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3993, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2019, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1844, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5798, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5804, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3363, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6535, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3115, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3064, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2983, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6955, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6498, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2398, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5940, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9962, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6586, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6100, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3930, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2046, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6964, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7509, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6521, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9993, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9994, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4933, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 4 finished ! Training Loss: 0.5992\n",
      "\n",
      "tensor(0.2746, device='cuda:0')\n",
      "tensor(0.9653, device='cuda:0')\n",
      "tensor(0.7310, device='cuda:0')\n",
      "tensor(0.6156, device='cuda:0')\n",
      "tensor(0.3425, device='cuda:0')\n",
      "tensor(0.4517, device='cuda:0')\n",
      "tensor(0.4254, device='cuda:0')\n",
      "tensor(0.6032, device='cuda:0')\n",
      "tensor(0.2407, device='cuda:0')\n",
      "tensor(0.4349, device='cuda:0')\n",
      "tensor(0.4786, device='cuda:0')\n",
      "tensor(0.2879, device='cuda:0')\n",
      "tensor(0.2684, device='cuda:0')\n",
      "tensor(0.3301, device='cuda:0')\n",
      "tensor(0.3044, device='cuda:0')\n",
      "tensor(0.7314, device='cuda:0')\n",
      "tensor(0.2715, device='cuda:0')\n",
      "tensor(0.5894, device='cuda:0')\n",
      "tensor(0.6448, device='cuda:0')\n",
      "tensor(0.3015, device='cuda:0')\n",
      "tensor(0.3838, device='cuda:0')\n",
      "tensor(0.4374, device='cuda:0')\n",
      "tensor(0.6244, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/4999 [49:51<1042:18:58, 751.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 4 saved !\n",
      "------- 1st valloss=0.4669\n",
      "\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6367, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3139, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1729, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9788, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2349, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4500, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6617, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6417, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2663, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4203, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3288, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3671, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6153, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2968, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4290, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7147, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7803, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3249, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4266, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5670, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2627, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4166, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7227, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4958, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5684, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5368, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2032, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6509, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2960, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7263, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7955, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4656, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6462, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6270, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3030, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2237, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2030, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6116, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6312, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9242, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6535, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6125, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3440, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6665, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5202, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6188, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7120, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3609, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3863, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5903, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2666, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3601, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6188, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/4999 [1:01:32<1021:08:54, 736.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished ! Training Loss: 0.5938\n",
      "\n",
      "tensor(0.3196, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6511, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6498, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2704, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2912, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2589, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8279, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4477, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7599, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7389, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6239, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6474, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5968, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6477, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3818, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5931, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9726, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4879, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6230, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6005, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6114, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1761, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7542, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3099, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2612, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5460, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6741, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6479, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9992, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6443, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9980, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6377, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4154, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4059, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4253, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3353, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6140, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7396, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3608, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3276, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8482, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6605, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1810, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4812, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2840, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6366, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8270, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2616, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5794, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6276, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3761, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6053, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7813, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3339, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3446, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6046, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6740, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6516, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 6 finished ! Training Loss: 0.5934\n",
      "\n",
      "tensor(0.2892, device='cuda:0')\n",
      "tensor(0.3357, device='cuda:0')\n",
      "tensor(0.2842, device='cuda:0')\n",
      "tensor(0.2775, device='cuda:0')\n",
      "tensor(0.2220, device='cuda:0')\n",
      "tensor(0.2250, device='cuda:0')\n",
      "tensor(0.2858, device='cuda:0')\n",
      "tensor(0.3040, device='cuda:0')\n",
      "tensor(0.2311, device='cuda:0')\n",
      "tensor(0.4658, device='cuda:0')\n",
      "tensor(0.2423, device='cuda:0')\n",
      "tensor(0.2904, device='cuda:0')\n",
      "tensor(0.3358, device='cuda:0')\n",
      "tensor(0.3333, device='cuda:0')\n",
      "tensor(0.3724, device='cuda:0')\n",
      "tensor(0.3890, device='cuda:0')\n",
      "tensor(0.3922, device='cuda:0')\n",
      "tensor(0.2816, device='cuda:0')\n",
      "tensor(0.4341, device='cuda:0')\n",
      "tensor(0.5298, device='cuda:0')\n",
      "tensor(0.2547, device='cuda:0')\n",
      "tensor(0.2602, device='cuda:0')\n",
      "tensor(0.1984, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/4999 [1:14:12<1030:48:24, 743.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 6 saved !\n",
      "------- 1st valloss=0.3145\n",
      "\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9951, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2421, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9967, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3359, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7207, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5810, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6717, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1978, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3497, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2114, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2821, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6256, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6756, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6481, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6610, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2889, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6747, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7655, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2250, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2154, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9988, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6244, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5912, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6629, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9785, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2389, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5853, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9930, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2155, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5797, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6643, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6892, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2617, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8862, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4833, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7368, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6670, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3573, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7872, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6957, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7032, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8108, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9980, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6109, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7598, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6144, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3790, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6160, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3561, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2119, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2262, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3361, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2149, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3598, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7595, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4518, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3972, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9503, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5969, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3111, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2943, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/4999 [1:25:53<1013:00:18, 730.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 finished ! Training Loss: 0.5734\n",
      "\n",
      "tensor(0.5853, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9835, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2550, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3232, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6370, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5437, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5284, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7132, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7901, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7262, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2520, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6039, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3361, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8380, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7119, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4961, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4346, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7507, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2219, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3295, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3819, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7151, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6017, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6334, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6080, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2001, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7654, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9919, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6113, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6250, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2562, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5962, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6296, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1778, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8347, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4004, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5547, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6691, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9984, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2443, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2810, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2132, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6940, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6505, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5734, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3869, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6279, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3187, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6015, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5159, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7870, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2495, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3892, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2958, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2688, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7240, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7399, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2255, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 8 finished ! Training Loss: 0.5786\n",
      "\n",
      "tensor(0.3136, device='cuda:0')\n",
      "tensor(0.2947, device='cuda:0')\n",
      "tensor(0.3014, device='cuda:0')\n",
      "tensor(0.1534, device='cuda:0')\n",
      "tensor(0.3853, device='cuda:0')\n",
      "tensor(0.2925, device='cuda:0')\n",
      "tensor(0.3116, device='cuda:0')\n",
      "tensor(0.3733, device='cuda:0')\n",
      "tensor(0.4142, device='cuda:0')\n",
      "tensor(0.2851, device='cuda:0')\n",
      "tensor(0.2491, device='cuda:0')\n",
      "tensor(0.3104, device='cuda:0')\n",
      "tensor(0.5295, device='cuda:0')\n",
      "tensor(0.4176, device='cuda:0')\n",
      "tensor(0.2879, device='cuda:0')\n",
      "tensor(0.2313, device='cuda:0')\n",
      "tensor(0.2880, device='cuda:0')\n",
      "tensor(0.3874, device='cuda:0')\n",
      "tensor(0.2438, device='cuda:0')\n",
      "tensor(0.3789, device='cuda:0')\n",
      "tensor(0.2494, device='cuda:0')\n",
      "tensor(0.6013, device='cuda:0')\n",
      "tensor(0.2881, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/4999 [1:38:32<1024:39:19, 739.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 8 saved !\n",
      "------- 1st valloss=0.3299\n",
      "\n",
      "tensor(0.4288, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4239, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6396, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4157, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6596, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6053, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3281, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2866, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3167, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6441, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6695, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4505, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2819, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3231, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3307, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9191, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6948, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5668, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6278, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7017, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3034, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3224, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3825, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6010, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6590, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6045, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2006, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6320, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5986, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6332, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2704, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6154, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6360, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2516, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7155, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5279, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7329, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7028, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2176, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3062, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8487, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6590, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6089, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3736, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6676, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7404, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5106, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3611, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2747, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6436, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3996, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3034, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4130, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6512, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3447, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7128, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3753, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6329, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6187, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/4999 [1:50:22<1012:39:38, 730.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 finished ! Training Loss: 0.5544\n",
      "\n",
      "tensor(0.2891, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5817, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5922, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6072, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6320, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4346, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7892, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7438, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6381, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9950, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9505, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6186, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3199, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3181, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2880, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6171, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5705, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9607, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4244, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3346, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6524, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6665, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5967, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8196, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2672, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4534, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2725, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6631, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7546, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9099, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6417, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1901, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3127, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5103, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1917, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6098, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9366, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3960, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9891, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6658, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3148, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2498, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2124, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6773, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2550, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3687, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6376, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5607, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4538, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7270, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7369, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9894, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1905, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3677, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4159, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2536, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3008, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2776, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3897, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6486, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6519, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 10 finished ! Training Loss: 0.5702\n",
      "\n",
      "tensor(0.2100, device='cuda:0')\n",
      "tensor(0.4274, device='cuda:0')\n",
      "tensor(0.3205, device='cuda:0')\n",
      "tensor(0.3858, device='cuda:0')\n",
      "tensor(0.2937, device='cuda:0')\n",
      "tensor(0.2759, device='cuda:0')\n",
      "tensor(0.3156, device='cuda:0')\n",
      "tensor(0.4088, device='cuda:0')\n",
      "tensor(0.3077, device='cuda:0')\n",
      "tensor(0.2223, device='cuda:0')\n",
      "tensor(0.4782, device='cuda:0')\n",
      "tensor(0.2853, device='cuda:0')\n",
      "tensor(0.1733, device='cuda:0')\n",
      "tensor(0.3183, device='cuda:0')\n",
      "tensor(0.3003, device='cuda:0')\n",
      "tensor(0.2765, device='cuda:0')\n",
      "tensor(0.5294, device='cuda:0')\n",
      "tensor(0.2558, device='cuda:0')\n",
      "tensor(0.2940, device='cuda:0')\n",
      "tensor(0.4465, device='cuda:0')\n",
      "tensor(0.3604, device='cuda:0')\n",
      "tensor(0.3182, device='cuda:0')\n",
      "tensor(0.2409, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/4999 [2:03:04<1025:18:37, 739.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 10 saved !\n",
      "------- 1st valloss=0.3237\n",
      "\n",
      "tensor(0.3721, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7161, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3040, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6202, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2662, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6576, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5411, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6183, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6539, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3057, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8348, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6022, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5791, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2724, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6158, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2187, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4164, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2777, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6706, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3808, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6227, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1674, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3870, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6398, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3412, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6264, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3499, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6108, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2487, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5758, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2860, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7037, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2373, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9883, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2495, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2727, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5693, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3774, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2160, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6550, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6016, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2344, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2373, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4264, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9286, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6634, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4287, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6414, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2853, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7808, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7245, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7388, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4754, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4633, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6709, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2303, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3537, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 11/4999 [2:14:47<1009:56:34, 728.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 finished ! Training Loss: 0.5192\n",
      "\n",
      "tensor(0.6685, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3641, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3679, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2921, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5998, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6670, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9846, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2737, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4783, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6033, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7002, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1974, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4147, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5614, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1487, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2795, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2393, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6364, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8054, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2236, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3070, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6066, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2906, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1990, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7995, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5882, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5904, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2069, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6226, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6647, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6061, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7125, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6207, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7449, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6200, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5959, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2597, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2768, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3638, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3270, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3110, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9761, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3108, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6128, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4001, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5749, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3003, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3065, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5724, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6015, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1637, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5728, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6028, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6065, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2413, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8146, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3394, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9927, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7116, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2381, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2339, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6742, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 12 finished ! Training Loss: 0.5305\n",
      "\n",
      "tensor(0.2787, device='cuda:0')\n",
      "tensor(0.2801, device='cuda:0')\n",
      "tensor(0.2673, device='cuda:0')\n",
      "tensor(0.3285, device='cuda:0')\n",
      "tensor(0.2979, device='cuda:0')\n",
      "tensor(0.3901, device='cuda:0')\n",
      "tensor(0.2197, device='cuda:0')\n",
      "tensor(0.3627, device='cuda:0')\n",
      "tensor(0.2781, device='cuda:0')\n",
      "tensor(0.4980, device='cuda:0')\n",
      "tensor(0.1891, device='cuda:0')\n",
      "tensor(0.5117, device='cuda:0')\n",
      "tensor(0.3154, device='cuda:0')\n",
      "tensor(0.2840, device='cuda:0')\n",
      "tensor(0.2279, device='cuda:0')\n",
      "tensor(0.2827, device='cuda:0')\n",
      "tensor(0.4000, device='cuda:0')\n",
      "tensor(0.2851, device='cuda:0')\n",
      "tensor(0.3161, device='cuda:0')\n",
      "tensor(0.2784, device='cuda:0')\n",
      "tensor(0.4222, device='cuda:0')\n",
      "tensor(0.2910, device='cuda:0')\n",
      "tensor(0.2336, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 12/4999 [2:27:24<1021:20:34, 737.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 12 saved !\n",
      "------- 1st valloss=0.3147\n",
      "\n",
      "tensor(0.3056, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6529, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3229, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6117, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2715, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7236, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7417, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9884, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6719, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9958, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6418, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2150, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2390, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6537, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8367, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2861, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1462, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9011, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2130, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2407, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7486, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1845, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6037, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6072, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5826, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2799, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3420, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4314, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3421, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5729, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9908, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9997, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7003, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3117, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7058, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6005, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6188, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3626, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7175, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5964, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2800, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4360, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2107, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2033, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4025, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6969, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6387, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1690, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6777, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9820, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3278, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3308, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9067, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1924, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3278, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5897, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3931, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2201, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3346, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3341, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 13/4999 [2:39:05<1006:04:59, 726.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 finished ! Training Loss: 0.5578\n",
      "\n",
      "tensor(0.5108, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3154, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7825, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3828, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6661, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2420, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5951, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2180, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2652, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3968, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4362, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5764, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3031, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6327, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2001, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7613, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2442, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2327, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2168, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5935, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4754, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3256, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2529, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3398, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6264, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1938, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2364, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3958, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2843, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6284, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6019, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6185, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3236, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2581, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9629, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3126, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5823, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2068, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1884, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6062, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5651, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7487, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1402, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1901, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9860, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3726, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6145, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3552, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5615, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6224, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6270, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1880, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5853, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1820, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 14 finished ! Training Loss: 0.5104\n",
      "\n",
      "tensor(0.1902, device='cuda:0')\n",
      "tensor(0.2053, device='cuda:0')\n",
      "tensor(0.4128, device='cuda:0')\n",
      "tensor(0.2309, device='cuda:0')\n",
      "tensor(0.2517, device='cuda:0')\n",
      "tensor(0.3027, device='cuda:0')\n",
      "tensor(0.2685, device='cuda:0')\n",
      "tensor(0.2075, device='cuda:0')\n",
      "tensor(0.2508, device='cuda:0')\n",
      "tensor(0.2947, device='cuda:0')\n",
      "tensor(0.2244, device='cuda:0')\n",
      "tensor(0.3116, device='cuda:0')\n",
      "tensor(0.1946, device='cuda:0')\n",
      "tensor(0.3045, device='cuda:0')\n",
      "tensor(0.5014, device='cuda:0')\n",
      "tensor(0.2872, device='cuda:0')\n",
      "tensor(0.2795, device='cuda:0')\n",
      "tensor(0.2767, device='cuda:0')\n",
      "tensor(0.2381, device='cuda:0')\n",
      "tensor(0.3366, device='cuda:0')\n",
      "tensor(0.3464, device='cuda:0')\n",
      "tensor(0.2236, device='cuda:0')\n",
      "tensor(0.3554, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 14/4999 [2:51:44<1019:16:51, 736.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 14 saved !\n",
      "------- 1st valloss=0.2824\n",
      "\n",
      "tensor(0.6181, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6185, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6900, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6030, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1547, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5694, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2206, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9978, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1777, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6263, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5753, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2102, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5713, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3148, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2183, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5981, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7439, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6420, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5740, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2126, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5771, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2816, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1784, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6261, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1830, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1609, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5842, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2751, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1577, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2508, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7708, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5997, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5527, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1745, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2379, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1455, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4290, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2368, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6432, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6357, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6787, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6482, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6585, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5897, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2775, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5458, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6235, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5702, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3969, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3972, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2049, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5399, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6444, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1647, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6982, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6269, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6577, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6483, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6275, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3141, device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 15/4999 [3:03:30<1006:48:36, 727.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 finished ! Training Loss: 0.4950\n",
      "\n",
      "tensor(0.3074, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6207, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9896, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2227, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3027, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5562, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4826, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2611, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5648, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9978, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2424, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7194, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5954, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1573, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2692, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5779, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2394, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8536, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2563, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6461, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7616, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5617, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6759, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6413, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6339, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6402, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5748, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7605, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6081, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9864, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7700, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5807, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3570, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6996, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5872, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2442, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3117, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2596, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5942, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5366, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6552, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2406, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3298, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6195, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2015, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2198, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3447, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6685, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6455, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2407, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6169, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1871, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5619, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1688, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2248, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2108, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3339, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2959, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7037, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7712, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5881, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2774, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 16 finished ! Training Loss: 0.5212\n",
      "\n",
      "tensor(0.2248, device='cuda:0')\n",
      "tensor(0.2094, device='cuda:0')\n",
      "tensor(0.3243, device='cuda:0')\n",
      "tensor(0.3100, device='cuda:0')\n",
      "tensor(0.1625, device='cuda:0')\n",
      "tensor(0.2735, device='cuda:0')\n",
      "tensor(0.2179, device='cuda:0')\n",
      "tensor(0.3199, device='cuda:0')\n",
      "tensor(0.3722, device='cuda:0')\n",
      "tensor(0.2960, device='cuda:0')\n",
      "tensor(0.2366, device='cuda:0')\n",
      "tensor(0.2565, device='cuda:0')\n",
      "tensor(0.4520, device='cuda:0')\n",
      "tensor(0.3701, device='cuda:0')\n",
      "tensor(0.3912, device='cuda:0')\n",
      "tensor(0.1545, device='cuda:0')\n",
      "tensor(0.2385, device='cuda:0')\n",
      "tensor(0.2450, device='cuda:0')\n",
      "tensor(0.3215, device='cuda:0')\n",
      "tensor(0.2730, device='cuda:0')\n",
      "tensor(0.2596, device='cuda:0')\n",
      "tensor(0.2412, device='cuda:0')\n",
      "tensor(0.3007, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 16/4999 [3:16:14<1021:45:07, 738.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 16 saved !\n",
      "------- 1st valloss=0.2805\n",
      "\n",
      "tensor(0.2619, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4333, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3462, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2999, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5901, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5966, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5544, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7772, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1818, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6128, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3032, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7322, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5885, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3265, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9975, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2226, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3142, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6502, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4033, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9978, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6741, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3430, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6035, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1528, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5378, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6059, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6908, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5697, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2598, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1775, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8924, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3272, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2296, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5925, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6459, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5660, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5641, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5845, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9954, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7594, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1896, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7289, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2765, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3198, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6028, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1580, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6368, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2433, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7113, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2920, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5710, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2135, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2208, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7573, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4388, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6007, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1881, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2821, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7237, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2284, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5786, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2010, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6115, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5942, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6290, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6550, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 17/4999 [3:27:52<1005:03:19, 726.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 finished ! Training Loss: 0.5115\n",
      "\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2068, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2749, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6309, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2399, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6016, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4188, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6551, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7990, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2130, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6187, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5751, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2401, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6388, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7109, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4292, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3646, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5680, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2369, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6007, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2187, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5800, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6100, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1490, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6189, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3210, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3906, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6008, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2064, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.1977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2305, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3488, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6404, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5144, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.9969, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6729, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4384, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8209, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2908, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5689, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5780, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5790, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1., device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2906, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3009, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2572, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5967, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6405, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3700, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2346, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.2437, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5821, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.7572, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.4881, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6289, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.5737, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3497, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.6264, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.3076, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 18 finished ! Training Loss: 0.5290\n",
      "\n",
      "tensor(0.3304, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "record = open('train_bv_refine_5.txt','a+')\n",
    "\n",
    "logger = {'train':[], 'validation_1': []}\n",
    "\n",
    "min_val = 1\n",
    "\n",
    "for e in tqdm(range(epoch + 1, epochs)):\n",
    "# iter over epoches\n",
    "    epoch_loss = 0\n",
    "        \n",
    "    for t, batch in enumerate(train_loader):\n",
    "    # iter over the train mini batches\n",
    "        refine_model.train()\n",
    "        deeplab.eval()\n",
    "        # Set the model flag to train\n",
    "        # 1. enable dropout\n",
    "        # 2. batchnorm behave differently in train and test\n",
    "        #print(batch['image1_data'])\n",
    "        image_1 = batch['image1_data'].to(device=device, dtype=dtype)\n",
    "        image_1 = image_1.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        label_1 = batch['image1_label'].to(device=device, dtype=dtype)\n",
    "        label_1 = label_1.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "        bv_label = label_1[:, 2, :, :, :]\n",
    "        bv_label = bv_label.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        #original_res = [a[minibatch].item() for a in batch['original_resolution']]\n",
    "\n",
    "        # Get coarse output from deeplab model from 256 resolution input\n",
    "        out_coarse = deeplab(image_1)\n",
    "        out_coarse = out_coarse.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "        bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "        bv_coarse = bv_coarse.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "        bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "        #bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "        \n",
    "        bbox_concat = torch.cat([bbox_image, bbox_bv], dim=1)\n",
    "        \n",
    "        #show_image_slice(label_1)\n",
    "        #show_image_slice(bv_label)\n",
    "        #show_image_slice(bbox_image)\n",
    "        #show_image_slice(bbox_label)\n",
    "        #show_image_slice(bbox_bv)\n",
    "\n",
    "        #print(\"bbox_concat\", bbox_concat.shape)\n",
    "\n",
    "        del out_coarse\n",
    "        del image_1\n",
    "        del bv_coarse\n",
    "        del label_1\n",
    "        del bv_label\n",
    "        del bbox_image\n",
    "        del bbox_bv\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        refine_out = refine_model(bbox_concat)\n",
    "        # do the inference\n",
    "\n",
    "        #print(refine_out.shape)\n",
    "        #print(bbox_bv_label.shape)\n",
    "\n",
    "        loss = dice_loss(refine_out, bbox_label)\n",
    "        \n",
    "        print(loss)\n",
    "        epoch_loss += loss.item()\n",
    "        # record minibatch loss to epoch loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # set the model parameter gradient to zero\n",
    "        \n",
    "        loss.backward()\n",
    "        # calculate the gradient wrt loss\n",
    "        optimizer.step()\n",
    "        # take a gradient descent step\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    outstr = 'Epoch {0} finished ! Training Loss: {1:.4f}'.format(e, epoch_loss/(t+1)) + '\\n'\n",
    "    \n",
    "    logger['train'].append(epoch_loss/(t+1))\n",
    "    \n",
    "    print(outstr)\n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "\n",
    "    if e%2 == 0:\n",
    "    # do validation every 5 epoches\n",
    "        deeplab.eval()\n",
    "        refine_model.eval()\n",
    "        # set model flag to eval\n",
    "        # 1. disable dropout\n",
    "        # 2. batchnorm behave differs\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # stop taking gradient\n",
    "        \n",
    "            #valloss_4 = 0\n",
    "            #valloss_2 = 0\n",
    "            valloss_1 = 0\n",
    "            \n",
    "            for v, vbatch in enumerate(validation_loader):\n",
    "                image_1 = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "                image_1 = image_1.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                label_1 = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "                label_1 = label_1.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "                bv_label = label_1[:, 2, :, :, :]\n",
    "                bv_label = bv_label.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                #original_res = [a[minibatch].item() for a in batch['original_resolution']]\n",
    "\n",
    "                # Get coarse output from deeplab model from 256 resolution input\n",
    "                out_coarse = deeplab(image_1)\n",
    "                out_coarse = out_coarse.view(BATCH_SIZE,3,256,256,256)\n",
    "\n",
    "                bv_coarse = out_coarse[:, 2, :, :, :]\n",
    "                bv_coarse = bv_coarse.view(BATCH_SIZE,1,256,256,256)\n",
    "\n",
    "                bbox_image, bbox_label, bbox_bv = get_bboxes(image_1, bv_label, bv_coarse, BATCH_SIZE)\n",
    "\n",
    "                bbox_concat = torch.cat([bbox_image, bbox_bv], dim=1)\n",
    "\n",
    "                #show_image_slice(label)\n",
    "                #show_image_slice(bbox_image)\n",
    "                #show_image_slice(bbox_label)\n",
    "                #show_image_slice(bbox_bv)\n",
    "\n",
    "                #print(\"bbox_concat\", bbox_concat.shape)\n",
    "                #seg_image_concat = torch.cat([bv_coarse, image_1], dim=1)\n",
    "\n",
    "                del out_coarse\n",
    "                del image_1\n",
    "                del bv_coarse\n",
    "                del label_1\n",
    "                del bv_label\n",
    "                del bbox_image\n",
    "                del bbox_bv\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                refine_out = refine_model(bbox_concat)\n",
    "                        \n",
    "                loss = dice_loss(refine_out, bbox_label)\n",
    "                \n",
    "                print(loss)\n",
    "            \n",
    "                # calculate loss\n",
    "                valloss_1 += loss.item()\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            \n",
    "            avg_val_loss = (valloss_1 / (v+1))\n",
    "            outstr = '------- 1st valloss={0:.4f}'\\\n",
    "                .format(avg_val_loss) + '\\n'\n",
    "            \n",
    "            logger['validation_1'].append(avg_val_loss)\n",
    "            #scheduler.step(avg_val_loss)\n",
    "            \n",
    "            if avg_val_loss < min_val:\n",
    "                save_1('refine_bv5_save', refine_model, optimizer, logger, e, scheduler)\n",
    "            elif e % 10 == 0:\n",
    "                save_1('refine_bv5_save', refine_model, optimizer, logger, e, scheduler)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            print(outstr)\n",
    "            record.write(outstr)\n",
    "            record.flush()\n",
    "    \n",
    "\n",
    "\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    bgloss = 0\n",
    "    bdloss = 0\n",
    "    bvloss = 0\n",
    "    \n",
    "    for v, vbatch in tqdm(enumerate(validation_loader)):\n",
    "        # move data to device, convert dtype to desirable dtype\n",
    "        image_1 = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "\n",
    "        output = deeplab(image_1)\n",
    "        # do the inference\n",
    "        output_numpy = output.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        #out_1 = torch.round(output)\n",
    "        out_1 = torch.from_numpy((output_numpy == output_numpy.max(axis=1)[:, None]).astype(int)).to(device=device, dtype=dtype)\n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "\n",
    "        bg, bd, bv = dice_loss_3_debug(out_1, label_1)\n",
    "        # calculate loss\n",
    "        print(bg.item(), bd.item(), bv.item(), loss_1.item())\n",
    "        bgloss += bg.item()\n",
    "        bdloss += bd.item()\n",
    "        bvloss += bv.item()\n",
    "        \n",
    "        if bv.item() >= 0.2 or bd.item() >= 0.1:\n",
    "            show_image_slice(image_1)\n",
    "            show_image_slice(label_1)\n",
    "            show_image_slice(output)\n",
    "\n",
    "    outstr = '------- background loss = {0:.4f}, body loss = {1:.4f}, bv loss = {2:.4f}'\\\n",
    "        .format(bgloss/(v+1), bdloss/(v+1), bvloss/(v+1)) + '\\n'\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
