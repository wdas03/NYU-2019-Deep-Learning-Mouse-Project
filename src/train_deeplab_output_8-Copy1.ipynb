{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utility import *\n",
    "from data_utils import *\n",
    "from loss import *\n",
    "from train import *\n",
    "from deeplab_model.deeplab import *\n",
    "from sync_batchnorm import convert_model\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU for training\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "NUM_WORKERS = 12\n",
    "BATCH_SIZE = 2 \n",
    "\n",
    "dtype = torch.float32 \n",
    "# define dtype, float is space efficient than double\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    # magic flag that accelerate\n",
    "    \n",
    "    print('using GPU for training')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pyramid_dataset(data_type = 'nii_train', \n",
    "                transform=transforms.Compose([\n",
    "                random_affine(90, 15),\n",
    "                random_filp(0.5)]))\n",
    "# do data augumentation on train dataset\n",
    "\n",
    "validation_dataset = pyramid_dataset(data_type = 'nii_test', \n",
    "                transform=None)\n",
    "# no data augumentation on validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=NUM_WORKERS) # drop_last\n",
    "# loaders come with auto batch division and multi-thread acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndeeplab = DeepLab(output_stride=8)\\ndeeplab = nn.DataParallel(deeplab)\\ndeeplab = convert_model(deeplab)\\ndeeplab = deeplab.to(device=device, dtype=dtype)\\n#shape_test(icnet1, True)\\n# create the model, by default model type is float, use model.double(), model.float() to convert\\n# move the model to desirable device\\n\\noptimizer = optim.Adam(deeplab.parameters(), lr=1e-2)\\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\\nepoch = 0\\n\\n# create an optimizer object\\n# note that only the model_2 params and model_4 params will be optimized by optimizer\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "deeplab = DeepLab(output_stride=8)\n",
    "deeplab = nn.DataParallel(deeplab)\n",
    "deeplab = convert_model(deeplab)\n",
    "deeplab = deeplab.to(device=device, dtype=dtype)\n",
    "#shape_test(icnet1, True)\n",
    "# create the model, by default model type is float, use model.double(), model.float() to convert\n",
    "# move the model to desirable device\n",
    "\n",
    "optimizer = optim.Adam(deeplab.parameters(), lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "epoch = 0\n",
    "\n",
    "# create an optimizer object\n",
    "# note that only the model_2 params and model_4 params will be optimized by optimizer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deeplab = DeepLab(output_stride=8)\n",
    "deeplab = nn.DataParallel(deeplab)\n",
    "deeplab = convert_model(deeplab)\n",
    "\n",
    "#checkpoint = torch.load('../deeplab_save/2019-07-29 04:00:14.630172.pth') # second best\n",
    "#checkpoint = torch.load('../deeplab_save/2019-07-28 23:47:36.279119.pth') # second best\n",
    "#checkpoint = torch.load('../deeplab_save/2019-07-29 00:15:49.271222.pth') # best\n",
    "#checkpoint = torch.load('../deeplab_save/2019-07-29 00:44:11.825872.pth')\n",
    "checkpoint = torch.load('../deeplab_output_8_3_save/2019-08-11 15:25:43.880400 epoch: 320.pth') # latest one\n",
    "\n",
    "deeplab.load_state_dict(checkpoint['state_dict_1'])\n",
    "deeplab = deeplab.to(device, dtype)\n",
    "\n",
    "optimizer = optim.Adam(deeplab.parameters(), lr=1e-3)\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(epoch)\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4679 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321 finished ! Training Loss: 0.0699\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/4679 [14:06<1099:34:39, 846.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 321 saved !\n",
      "Epoch 322 finished ! Training Loss: 0.0714\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/4679 [26:57<1070:11:30, 823.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 322 saved !\n",
      "Epoch 323 finished ! Training Loss: 0.0704\n",
      "\n",
      "------- 1st valloss=0.0920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/4679 [39:46<1048:33:05, 807.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 323 saved !\n",
      "Epoch 324 finished ! Training Loss: 0.0703\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/4679 [52:39<1034:54:15, 796.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 324 saved !\n",
      "Epoch 325 finished ! Training Loss: 0.0698\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/4679 [1:05:37<1027:30:56, 791.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 325 saved !\n",
      "Epoch 326 finished ! Training Loss: 0.0699\n",
      "\n",
      "------- 1st valloss=0.0911\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/4679 [1:18:38<1023:10:23, 788.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 326 saved !\n",
      "Epoch 327 finished ! Training Loss: 0.0693\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/4679 [1:31:26<1015:06:10, 782.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 327 saved !\n",
      "Epoch 328 finished ! Training Loss: 0.0695\n",
      "\n",
      "------- 1st valloss=0.0952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/4679 [1:44:18<1010:48:53, 779.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 328 saved !\n",
      "Epoch 329 finished ! Training Loss: 0.0701\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/4679 [1:57:09<1007:33:37, 776.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 329 saved !\n",
      "Epoch 330 finished ! Training Loss: 0.0696\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/4679 [2:09:58<1004:13:14, 774.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 330 saved !\n",
      "Epoch 331 finished ! Training Loss: 0.0700\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 11/4679 [2:23:00<1006:56:19, 776.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 331 saved !\n",
      "Epoch 332 finished ! Training Loss: 0.0702\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 12/4679 [2:35:59<1007:46:59, 777.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 332 saved !\n",
      "Epoch 333 finished ! Training Loss: 0.0705\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 13/4679 [2:48:49<1004:47:07, 775.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 333 saved !\n",
      "Epoch 334 finished ! Training Loss: 0.0711\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 14/4679 [3:01:50<1006:55:53, 777.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 334 saved !\n",
      "Epoch 335 finished ! Training Loss: 0.0704\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 15/4679 [3:14:41<1004:04:49, 775.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 335 saved !\n",
      "Epoch 336 finished ! Training Loss: 0.0707\n",
      "\n",
      "------- 1st valloss=0.0930\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 16/4679 [3:27:28<1001:01:16, 772.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 336 saved !\n",
      "Epoch 337 finished ! Training Loss: 0.0706\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 17/4679 [3:40:19<1000:08:03, 772.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 337 saved !\n",
      "Epoch 338 finished ! Training Loss: 0.0699\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 18/4679 [3:53:14<1000:45:26, 772.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 338 saved !\n",
      "Epoch 339 finished ! Training Loss: 0.0697\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 19/4679 [4:06:02<998:43:55, 771.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 339 saved !\n",
      "Epoch 340 finished ! Training Loss: 0.0703\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 20/4679 [4:18:52<997:43:36, 770.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 340 saved !\n",
      "Epoch 341 finished ! Training Loss: 0.0696\n",
      "\n",
      "------- 1st valloss=0.0923\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 21/4679 [4:31:41<996:53:18, 770.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 341 saved !\n",
      "Epoch 342 finished ! Training Loss: 0.0707\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 22/4679 [4:44:30<995:57:16, 769.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 342 saved !\n",
      "Epoch 343 finished ! Training Loss: 0.0697\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 23/4679 [4:57:16<994:11:18, 768.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 343 saved !\n",
      "Epoch 344 finished ! Training Loss: 0.0702\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 24/4679 [5:10:03<993:35:06, 768.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 344 saved !\n",
      "Epoch 345 finished ! Training Loss: 0.0713\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 25/4679 [5:22:53<994:00:18, 768.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 345 saved !\n",
      "Epoch 346 finished ! Training Loss: 0.0696\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 26/4679 [5:35:45<994:52:37, 769.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 346 saved !\n",
      "Epoch 347 finished ! Training Loss: 0.0702\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 27/4679 [5:48:47<999:28:50, 773.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 347 saved !\n",
      "Epoch 348 finished ! Training Loss: 0.0705\n",
      "\n",
      "------- 1st valloss=0.0650\n",
      "\n",
      "0.06503271230536958 less than 0.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 28/4679 [6:01:51<1003:14:21, 776.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 348 saved !\n",
      "Epoch 349 finished ! Training Loss: 0.0710\n",
      "\n",
      "------- 1st valloss=0.0934\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 29/4679 [6:14:49<1003:44:34, 777.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 349 saved !\n",
      "Epoch 350 finished ! Training Loss: 0.0703\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 30/4679 [6:27:42<1001:59:00, 775.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 350 saved !\n",
      "Epoch 351 finished ! Training Loss: 0.0708\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 31/4679 [6:40:39<1001:55:08, 776.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 351 saved !\n",
      "Epoch 352 finished ! Training Loss: 0.0697\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 32/4679 [6:53:33<1001:01:47, 775.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 352 saved !\n",
      "Epoch 353 finished ! Training Loss: 0.0714\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 33/4679 [7:06:32<1002:16:23, 776.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 353 saved !\n",
      "Epoch 354 finished ! Training Loss: 0.0692\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 34/4679 [7:19:22<999:34:32, 774.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 354 saved !\n",
      "Epoch 355 finished ! Training Loss: 0.0697\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 35/4679 [7:32:13<997:56:59, 773.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 355 saved !\n",
      "Epoch 356 finished ! Training Loss: 0.0694\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 36/4679 [7:45:14<1000:16:29, 775.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 356 saved !\n",
      "Epoch 357 finished ! Training Loss: 0.0694\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 37/4679 [7:58:08<999:27:02, 775.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 357 saved !\n",
      "Epoch 358 finished ! Training Loss: 0.0699\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 38/4679 [8:10:53<995:27:41, 772.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 358 saved !\n",
      "Epoch 359 finished ! Training Loss: 0.0708\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 39/4679 [8:23:52<997:47:04, 774.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 359 saved !\n",
      "Epoch 360 finished ! Training Loss: 0.0698\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 40/4679 [8:36:53<1000:16:14, 776.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 360 saved !\n",
      "Epoch 361 finished ! Training Loss: 0.0703\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 41/4679 [8:49:46<999:02:27, 775.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 361 saved !\n",
      "Epoch 362 finished ! Training Loss: 0.0703\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 42/4679 [9:02:36<996:38:05, 773.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 362 saved !\n",
      "Epoch 363 finished ! Training Loss: 0.0696\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 43/4679 [9:15:39<1000:01:17, 776.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 363 saved !\n",
      "Epoch 364 finished ! Training Loss: 0.0700\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 44/4679 [9:28:43<1002:43:04, 778.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 364 saved !\n",
      "Epoch 365 finished ! Training Loss: 0.0703\n",
      "\n",
      "------- 1st valloss=nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 45/4679 [9:41:28<997:10:29, 774.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 365 saved !\n",
      "Epoch 366 finished ! Training Loss: 0.0712\n",
      "\n",
      "------- 1st valloss=0.0908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 46/4679 [9:54:18<995:01:10, 773.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 366 saved !\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "min_val = 0.0778\n",
    "\n",
    "record = open('train_deeplab_output_8_3.txt','a+')\n",
    "\n",
    "logger = {'train':[], 'validation_1': []}\n",
    "\n",
    "for e in tqdm(range(epoch + 1, epochs)):\n",
    "# iter over epoches\n",
    "\n",
    "    epoch_loss = 0\n",
    "        \n",
    "    for t, batch in enumerate(train_loader):\n",
    "    # iter over the train mini batches\n",
    "    \n",
    "        deeplab.train()\n",
    "        # Set the model flag to train\n",
    "        # 1. enable dropout\n",
    "        # 2. batchnorm behave differently in train and test\n",
    "        \n",
    "        image_1 = batch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = batch['image1_label'].to(device=device, dtype=dtype)\n",
    "        # move data to device, convert dtype to desirable dtype\n",
    "        \n",
    "        out_1 = deeplab(image_1)\n",
    "        # do the inference\n",
    "\n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "        # calculate loss\n",
    "        \n",
    "        epoch_loss += loss_1.item()\n",
    "        # record minibatch loss to epoch loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # set the model parameter gradient to zero\n",
    "        \n",
    "        loss_1.backward()\n",
    "        # calculate the gradient wrt loss\n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss_1)\n",
    "        # take a gradient descent step\n",
    "        \n",
    "    outstr = 'Epoch {0} finished ! Training Loss: {1:.4f}'.format(e, epoch_loss/(t+1)) + '\\n'\n",
    "    \n",
    "    logger['train'].append(epoch_loss/(t+1))\n",
    "    \n",
    "    print(outstr)\n",
    "    record.write(outstr)\n",
    "    record.flush()\n",
    "\n",
    "    if e%1 == 0:\n",
    "    # do validation every 5 epoches\n",
    "    \n",
    "        deeplab.eval()\n",
    "        # set model flag to eval\n",
    "        # 1. disable dropout\n",
    "        # 2. batchnorm behave differs\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # stop taking gradient\n",
    "        \n",
    "            #valloss_4 = 0\n",
    "            #valloss_2 = 0\n",
    "            valloss_1 = 0\n",
    "            \n",
    "            for v, vbatch in enumerate(validation_loader):\n",
    "            # iter over validation mini batches\n",
    "                \n",
    "                image_1_val = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "                if get_dimensions(image_1_val) == 4:\n",
    "                    image_1_val.unsqueeze_(0)\n",
    "                label_1_val = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "                if get_dimensions(label_1_val) == 4:\n",
    "                    label_1_val.unsqueeze_(0)\n",
    "                # move data to device, convert dtype to desirable dtype\n",
    "                # add one dimension to labels if they are 4D tensors\n",
    "                \n",
    "                out_1_val = deeplab(image_1_val)\n",
    "                # do the inference\n",
    "                \n",
    "                loss_1 = dice_loss_3(out_1_val, label_1_val)\n",
    "                # calculate loss\n",
    "\n",
    "                valloss_1 += loss_1.item()\n",
    "                # record mini batch loss\n",
    "            \n",
    "            avg_val_loss = (valloss_1 / (v+1))\n",
    "            outstr = '------- 1st valloss={0:.4f}'\\\n",
    "                .format(avg_val_loss) + '\\n'\n",
    "            \n",
    "            logger['validation_1'].append(avg_val_loss)\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            print(outstr)\n",
    "            record.write(outstr)\n",
    "            record.flush()\n",
    "            \n",
    "            if avg_val_loss < min_val:\n",
    "                print(avg_val_loss, \"less than\", min_val)\n",
    "                min_val = avg_val_loss\n",
    "                \n",
    "            save_1('deeplab_output_8_3_save', deeplab, optimizer, logger, e, scheduler)\n",
    "\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    bgloss = 0\n",
    "    bdloss = 0\n",
    "    bvloss = 0\n",
    "    \n",
    "    for v, vbatch in tqdm(enumerate(validation_loader)):\n",
    "            # move data to device, convert dtype to desirable dtype\n",
    "\n",
    "        image_1 = vbatch['image1_data'].to(device=device, dtype=dtype)\n",
    "        label_1 = vbatch['image1_label'].to(device=device, dtype=dtype)\n",
    "\n",
    "        output = deeplab(image_1)\n",
    "        # do the inference\n",
    "        output_numpy = output.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        #out_1 = torch.round(output)\n",
    "        out_1 = torch.from_numpy((output_numpy == output_numpy.max(axis=1)[:, None]).astype(int)).to(device=device, dtype=dtype)\n",
    "        loss_1 = dice_loss_3(out_1, label_1)\n",
    "\n",
    "        bg, bd, bv = dice_loss_3_debug(out_1, label_1)\n",
    "        # calculate loss\n",
    "        print(bg.item(), bd.item(), bv.item(), loss_1.item())\n",
    "        bgloss += bg.item()\n",
    "        bdloss += bd.item()\n",
    "        bvloss += bv.item()\n",
    "\n",
    "    outstr = '------- background loss = {0:.4f}, body loss = {1:.4f}, bv loss = {2:.4f}'\\\n",
    "        .format(bgloss/(v+1), bdloss/(v+1), bvloss/(v+1)) + '\\n'\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
